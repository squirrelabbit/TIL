# idmax()

 [`DataFrame.idxmax()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) 함수는 행에서 최대 값의 색인을 반환

# sort_values()

![image-20220304145002538](데이터프레임.assets/image-20220304145002538.png)

```py
suicide_data.sort_values(by='Education')
```

```
data_gu = data_gu.sort_values(by="비중",ascending = False,ignore_index= True)
```

# 빈칸삭제

![image-20220210110338311](데이터프레임.assets/image-20220210110338311.png)

참조 페이지 https://stackoverflow.com/questions/29314033

 https://codesample-factory.tistory.com/1081



# 합치기

## 1. merge()

 pd.merge()함수에서는 첫 번째 인수 left와 두 번째 인수 right를 결합하는 두 개의 pandas.DataFrame을 지정한다.

```
print(pd.merge(df_ab, df_ac))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
```

 merger()메소드의 경우는 left에 해당하는 pandas.DataFrame에서 부터 메소드를 호출하고, right에 해당하는 pandas.DataFrame를 인수로써 지정한다.

```
print(df_ab.merge(df_ac))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
```

 어느쪽의 방법이든 결합된 pandas.DataFrame가 반환된다.

 아래에서 설명하는 인수는 pd.merge()메소드에서도 merge()메소드에도 동일하다.

 

 

 **키가 되는 열을 지정: 인수on, left_on, right_on**

------

 기본적으로 2개의 pandas.DataFrame에 공통되는 열 이름을 키로 하여 결합 처리가 이루어진다.

 명시적으로 지정하는 경우에는 인수 on을 사용한다. 생략해도 문제가 없지만, 명시해두는 것이 나중에 다시 봤을 때에도 알기 쉬울 것이다.

```
print(pd.merge(df_ab, df_ac, on='a'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
```

 인수 left_on, right_on으로 각각의 pandas.DataFrame의 열 이름을 각각 지정하는 것도 가능하다.

```
df_ac_ = df_ac.rename(columns={'a': 'a_'})
print(df_ac_)
#     a_    c
# 0  a_1  c_1
# 1  a_2  c_2
# 2  a_4  c_4

print(pd.merge(df_ab, df_ac_, left_on='a', right_on='a_'))
#      a    b   a_    c
# 0  a_1  b_1  a_1  c_1
# 1  a_2  b_2  a_2  c_2
```

 이 경우, 두 개의 열이 남으므로, 필요하지 않는 열에 대해서는 drop()메소드를 이용해서 삭제해줘야한다. 사용법은 다음과 같다.

```
print(pd.merge(df_ab, df_ac_, left_on='a', right_on='a_').drop(columns='a_'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
```

 on, left_on, right_on에 열 이름의 리스트를 짖어하여 여러 개의 열을 키로써 지정하는 것이 가능하다. 그에 대한 내용은 뒤에서 설명하도록 하겠다.

 

 

 **결합 방법을 지정: 인수how**

------

 결합방법은 인수 how의 문자열로 지정한다. 기본적으로는 how='inner'이다. 데이터가 없는 요소는 결손값 Nan이 된다. 

 **inner_join : how='inner'**

```
print(pd.merge(df_ab, df_ac, on='a', how='inner'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
```

 **left_join : how='left'**

```
print(pd.merge(df_ab, df_ac, on='a', how='left'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
# 2  a_3  b_3  NaN
```

 **right_join : how='right'**

```
print(pd.merge(df_ab, df_ac, on='a', how='right'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
# 2  a_4  NaN  c_4
```

 **outer_join : how='outer'**

```
print(pd.merge(df_ab, df_ac, on='a', how='outer'))
#      a    b    c
# 0  a_1  b_1  c_1
# 1  a_2  b_2  c_2
# 2  a_3  b_3  NaN
# 3  a_4  NaN  c_4
```

 

 

 **데이터의 정보를 취득 : 인수indicator**

------

인수 indicator를 True로 하면, 원래 데이터의 정보를 포함한 열이 추가된다.

기본적으로 _merge이라는 행이 추가되어, both, left_only, right_only중 하나로 분류된다.

```
print(pd.merge(df_ab, df_ac, on='a', how='inner', indicator=True))
#      a    b    c _merge
# 0  a_1  b_1  c_1   both
# 1  a_2  b_2  c_2   both

print(pd.merge(df_ab, df_ac, on='a', how='outer', indicator=True))
#      a    b    c      _merge
# 0  a_1  b_1  c_1        both
# 1  a_2  b_2  c_2        both
# 2  a_3  b_3  NaN   left_only
# 3  a_4  NaN  c_4  right_only
```

_merge가 아닌 임의의 열 명으로 하고 싶은 경우에는 인수 indicator에 문자열을 지정한다.

```
print(pd.merge(df_ab, df_ac, on='a', how='outer', indicator='indicator'))
#      a    b    c   indicator
# 0  a_1  b_1  c_1        both
# 1  a_2  b_2  c_2        both
# 2  a_3  b_3  NaN   left_only
# 3  a_4  NaN  c_4  right_only
```

출처: https://engineer-mole.tistory.com/208 [매일 꾸준히, 더 깊이]

## concat()

1-1. `pd.concat()`의 옵션

두 데이터프레임은 행인덱스와 열인덱스가 다르다.

```
result1 = pd.concat([df1,df2])
print(result1)
[Output]
    a   b   c    d
0  a0  b0  c0  NaN
1  a1  b1  c1  NaN
2  a2  b2  c2  NaN
3  a3  b3  c3  NaN
2  a2  b2  c2   d2
3  a3  b3  c3   d3
4  a4  b4  c4   d4
5  a5  b5  c5   d5 
```

defalut값으로 `axis=0`이 적용되기 때문에 행방향(위아래)으로 데이터프레임을 이어붙인다.
그런데 df1에는 d열이 없으므로 NaN값이 채워진 것을 알 수 있다.



그냥 이어붙이니 행 인덱스번호도 그대로 가져왔기때문에, `ignore_index=True`을 줘서 인덱스를 재배열 할 수 있다.

```
result2 = pd.concat([df1,df2], ignore_index=True)
print(result2)
[Output]
    a   b   c    d
0  a0  b0  c0  NaN
1  a1  b1  c1  NaN
2  a2  b2  c2  NaN
3  a3  b3  c3  NaN
4  a2  b2  c2   d2
5  a3  b3  c3   d3
6  a4  b4  c4   d4
7  a5  b5  c5   d5 
```

이번에는 열방향`axis=1`(좌우)으로 이어붙여보자.

```
result3 = pd.concat([df1,df2],axis=1)
print(result3)
[Output]
     a    b    c    a    b    c    d
0   a0   b0   c0  NaN  NaN  NaN  NaN
1   a1   b1   c1  NaN  NaN  NaN  NaN
2   a2   b2   c2   a2   b2   c2   d2
3   a3   b3   c3   a3   b3   c3   d3
4  NaN  NaN  NaN   a4   b4   c4   d4
5  NaN  NaN  NaN   a5   b5   c5   d5 
```



`pd.concat()`함수는 또한 default로 outer를 가진다.
이어붙이는 방식을 outer는 합집합, inner는 교집합을 의미한다.

그러면 이번에는 inner옵션을 줘서 이어붙일 두 데이터에 모두 존재하는 행인덱스만 가져와보자.

```
result3_in = pd.concat([df1,df2],axis=1, join='inner')   #열방향(axis=1), 교집합(inner)
print(result3_in)
[Output]
    a   b   c   a   b   c   d
2  a2  b2  c2  a2  b2  c2  d2
3  a3  b3  c3  a3  b3  c3  d3 
```

1-2. 시리즈를 데이터프레임에 붙이기

시리즈 객체도 마찬가지로 이어붙이기가 가능하다.
시리즈 객체를 생성할때 주는 옵션 `name`이, 시리즈가 데이터프레임에 결합되었을 떄의 열이름이 된다.

```
sr1 = pd.Series(['e0','e1','e2','e3'], name = 'e')
sr2 = pd.Series(['f0','f1','f2'], name = 'f', index = [3,4,5])
sr3 = pd.Series(['g0','g1','g2','g3'], name = 'g')
```



```
result4 = pd.concat([df1,sr1], axis=1)
print(result4, '\n')

result5 = pd.concat([df2,sr2], axis=1)
print(result5, '\n')
[Output]
    a   b   c   e
0  a0  b0  c0  e0
1  a1  b1  c1  e1
2  a2  b2  c2  e2
3  a3  b3  c3  e3 

    a   b   c   d    f
2  a2  b2  c2  d2  NaN
3  a3  b3  c3  d3   f0
4  a4  b4  c4  d4   f1
5  a5  b5  c5  d5   f2 
```

sr2의 `name`은 f, `index`는 3,4,5로 지정해줬으므로, 해당 행인덱스에 맞춰 이어붙여졌음을 볼 수 있다.

1-3. 시리즈 끼리 붙이기

```
result6 = pd.concat([sr1, sr3], axis = 1)  #열방향 연결, 데이터프레임
print(result6)
print(type(result6), '\n')

result7 = pd.concat([sr1, sr3], axis = 0)  #행방향 연결, 시리즈
print(result7)
print(type(result7), '\n') 
[Output]
    e   g
0  e0  g0
1  e1  g1
2  e2  g2
3  e3  g3
<class 'pandas.core.frame.DataFrame'> 

0    e0
1    e1
2    e2
3    e3
0    g0
1    g1
2    g2
3    g3
dtype: object
<class 'pandas.core.series.Series'> 
```



sr1에는 인덱스를 지정해주지 않았으므로 자동으로 0,1,2,3이 들어갔을 것이다. 그래서 바로 열방향 concat이 되었고,
두 시리즈를 행방향(axis=0)연결을 하게되면 여전히 시리즈객체로 반환됨을 알 수 있다.

# column 끼리 연산

specialscene 2019. 12. 10. 23:19

**(상황)**

데이터 프레임이 아래와 같을때 column1과 column2의 코사인 유사도를 계산하려고 한다

 

**(데이터)**

df로 명명

| idx  | column1 | column2 | column3 |
| ---- | ------- | ------- | ------- |
| 1    | [1,0,1] | [1,1,0] |         |

 

```
# cosin_similarity를 구하기 위한 라이브러리 import
from sklearn.metrics.pairwise import cosine_similarity

# cosine_similariy 계산해줄 수 있는 함수 cos_sim 정의
# 인자 a,b는 list형식으로 들어온다고 가정
# reshape은 계산 가능한 형태로 만들어주기 위해 해주는 것
def cos_sim(a,b):
    similarity = cosine_similarity(np.array(a).reshape(1,len(a)), np.array(b).reshape(1,len(a)))
    return similarity[0][0]

df['column3'] = df.apply(lambda x: cos_sim(x['column1'], x['column2']), axis=1)
```

**(이렇게 이해하면 쉬웠음)**

df.apply(lambda x: 어쩌구 저쩌구)를 써주면 for문 없이 row들이 순서대로 들어가

x로 받는다고 생각하면 이해하기 쉬웠음

 

 

**(이렇게 해줄때 편한점)**

예전에는 for문으로 코드를 억지로 만들어주는 느낌이 있었는데,

apply를 활용하면 좀 더 간결하게 column을 가지고 연산하여 새로운 column을 만들 수 있음

 

**(이걸 몰랐을때 당황했던 경험)**

\1) cosine_similarity함수의 인자로는 np.array형태가 들어가는데

cosine_similarity(df['column1'], df['column2'])는 안되니깐 어떻게해야할지 몰랐음

 

\2) for문으로 .iloc()을 이용해서 이상한 코드를 만들어서 썻었음



# 문자열 ->  숫자형

pandas Dataframe 에서 문자열 칼럼을 숫자형으로 바꿔야할 때가 종종 있습니다. 

그 때 쓰는 메서드는 보통 

 

pd.to_numeric() 

dataframe.astype()

 

이렇게 2가지가 있습니다. 

하나하나 살펴보겠습니다.

 



![img](https://blog.kakaocdn.net/dn/54tQ9/btqCpQsKh87/cGAO1ZxgsikACHkFDnz2RK/img.png)



**1) to_numeric()**

 

시리즈 데이터를 하나 만들었습니다. 여기에 pd.to_numeric( ) 을 하겠습니다.



![img](https://blog.kakaocdn.net/dn/bdQTeS/btqCjdpHZG8/HVZB99GskKQlEcWdKYvHmK/img.png)



시리즈 데이터로 넣었더니, 타입이 int 로 만들어진 것을 확인할 수 있습니다. 

근데, 만약에 dataframe으 모든 칼럼을 숫자형으로 바꾸고 싶다면 어떨까요? 

이 때는 apply 라는 메서드를 통해서 사용합니다. 

 

apply 메서드에 대해 잠깐 살펴보겠습니다. 

 



![img](https://blog.kakaocdn.net/dn/z3IhP/btqChGeNUNT/lrOijyDH7lTPtwaQtimCxK/img.png)



apply 메서드 안에는 커스텀함수나 기존의 메서드들을 인자로 넣어주시면 됩니다. 

한 칼럼의 최대값과 최소값의 차이를 리턴해주는 커스텀 함수 f 를 만들었구요. 

데이터프레임에 apply 를 썼더니 모든 칼럼에 f 함수가 적용된 것을 볼 수 있습니다.

 



![img](https://blog.kakaocdn.net/dn/diSYJd/btqCoQzMrPH/o63K9qI1L3TZyWLkFWOl31/img.png)



기본적으로 apply 는 칼럼을 중심으로 함수가 적용되는데 만약 인덱스별로 (가로로) 함수가 적용되게 하고 싶다면

axis='columns' 라는 인자를 넘기면 각 로우에 대해 한 번씩 함수를 수행합니다. 

 

자, 다시 to_numeric 으로 넘어오겠습니다. 

 



![img](https://blog.kakaocdn.net/dn/cc7CT6/btqCjeozxbx/wEJCGe4bY9shcKmLOwB8V1/img.png)



dataframe통째로 apply를 적용할 수 있지만, 위에서 보는 것처럼 특정 칼럼만 지정해서 to_numeric을 쓸 수도 있습니다.



![img](https://blog.kakaocdn.net/dn/baOFAd/btqCje3iN1P/ATsMtwLLfCh7w2NEdFH1Pk/img.png)



통째로 적용하고 싶다면 데이터프레임의 변수명을 그대로 apply 앞에 적어주시고 메서드를 실행시켜주면 됩니다. 

참고로, apply 메서드 안에는 커스텀 함수가 아닌 pandas 에 있는 to_numeric 을 적어주었습니다.

커스텀 함수는 기존 만들어진 함수든 같은 '함수'라는 사실임을 헷갈리지 마시길! 

 

**2) astype()** 



![img](https://blog.kakaocdn.net/dn/caHc5z/btqCjdXswd1/77H1NjSgb0YgW9Al4BG8fk/img.png)



개인적으로 astype을 좀 더 선호하는데 뭔가 명시적으로 타입을 지정해주는 게 더 낫다고 생각하기 때문입니다. 

사용법은 앞에서 to_numeric 쓰는 법과 비슷합니다. 

astype은 그냥 단독으로 쓰고 타입만 인자로 전달해주면 되서 좀 덜 헷갈리는 느낌입니다. (제 기준입니다) 



![img](https://blog.kakaocdn.net/dn/bwACxK/btqCjRNtHHm/SfxtfpOMNZrgKfXOK9Tj91/img.png)



또한, 각 칼럼별 타입을 위와 같이 딕셔너리형태로 지정해줄 수도 있습니다. 



출처: https://sikaleo.tistory.com/39 [SIKALEO]