```
import pandas as pd
import numpy as np

data2 = pd.read_csv('Dataset_02.csv')
data2.columns
# ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']
```
# 1. 빈도값

```
q1 = data2[['Sex', 'BP', 'Cholesterol']].value_counts(normalize = True)

q1[('F','HIGH','NORMAL')]

#답 : 03105

```



# 2-1. 범주형 변환

```python
q2 = data2.copy()

q2['Age_gr'] = np.where(q2.Age < 20, 10,
                        np.where(q2.Age < 30, 20,
                                 np.where(q2.Age < 40, 30,
                                          np.where(q2.Age < 50, 40,
                                                   np.where(q2.Age < 60, 50,60)))))

q2['Na_K_gr'] = np.where(q2.Na_to_K <= 10, 'Lv1',
                         np.where(q2.Na_to_K <= 20, 'Lv2',
                                  np.where(q2.Na_to_K <= 30, 'Lv3', 'Lv4')))
```





# 2-2. 독립성 검정 :  t-test 

## (1) 빈도표

```
temp =pd.crosstab(index = q2['Sex'], columns = q2['Drug'])
```

## (2) 카이스퀘어 검정
```
from scipy.stats import chi2_contingency

chi2_contingency(temp)
```




## (3) 반복문으로 재편성
```
var_list = ['Sex', 'BP', 'Cholesterol', 'Age_gr', 'Na_K_gr']

from scipy.stats import chi2_contingency

q2_out = []
for i in var_list:
    temp =pd.crosstab(index = q2[i], columns = q2['Drug'])
    chi_out = chi2_contingency(temp)
    pvalue = chi_out[1]
    q2_out.append([i,pvalue])
```




## (4) 독립성 검정결과
>Drug 타입과 연관성이 있는 변수는 몇 개인가? 연관성이 있는 변수
가운데 가장 큰 p-value를 찾아 소수점 여섯 번째 자리 이하는 버리고 소수점 다섯

```
q2_out = pd.DataFrame(q2_out, columns = ['var','pvalue'])

q2_out2 = q2_out[q2_out.pvalue < 0.05]

len(q2_out2)
q2_out2.pvalue.max()
```



>답: 4, 0.00070



# 3. 의사결정나무(숫자데이터만)

분류? 회귀?: label에 따라서

## (1) 변수변환
q3 = data2.copy()

q3['Sex_cd'] = np.where(q3.Sex == 'M',0,1)
q3['BP_cd'] = np.where(q3.BP == 'LOW',0,
               np.where(q3.BP == 'NORMAL',1,2))
q3['Ch_cd'] = np.where(q3.Cholesterol == 'NORMAL',0,1)



## (2) 의사결정나무(분류)진행

from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text

var_list = ['Age', 'Na_to_K', 'Sex_cd', 'BP_cd', 'Ch_cd']

dt = DecisionTreeClassifier().fit(q3[var_list],q2['Drug'])



## (3) Root Node의 split feature와 split value를 기술

- 룰 확인: 시각화, 텍스트
  plot_tree(dt, max_depth = 2, feature_names = var_list, 
          class_names = list(q3.Drug.unique()),
          precision =3, fontsize =8)
  print(export_text(dt, decimals =3
                  ,feature_names = var_list))

>  답: Na_to_K, 14.829

## (4) dt.feature_importances_

> [0.13595415, 0.47628234, 0.        , 0.26571772, 0.12204579]

