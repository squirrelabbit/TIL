# 1.결측치

```
data1.isna().sum().sum()

#결측치가 포함된 행의 수 
data1.isna().any(axis=1).sum()
```



#.isna(),isnull():결측치찾기:any(),all(), np.nan, 
#dropna(): 결측치제거 
#.fillna() :결측치 변환 

# 2.상관관계

![image-20220321102741660](C:\Users\eunwon\AppData\Roaming\Typora\typora-user-images\image-20220321102741660.png)

0.2를 넘을때부터 상관관계를 보인다

0.6이상이 유의미

=> 상관관계의 절대치가 클수로 높은 상관관계

```
val_list= ['TV', 'Radio', 'Social_Media', 'Sales']
q2 = data1[val_list].corr().drop('Sales')['Sales'].abs()

q2.max() # 최대값
q2.idmax() #최대값이 있는 인덱스명
q2.argmax() #최대값이 있는 위치번호
q2.nlargest(1) #시리즈 전용함수 최대값과 인덱스명을 리턴
```

## 반올림
round(q2.max(),4)
#답: 0.9995
#상관관계가 강한 2개의 변수
q2.nlargest(2).index

# 3. 회귀분석
## LinearRegression
유의미: statesmodels

```python
from sklearn.linear_model import LinearRegression # 선형회귀 상수함 포함
from statsmodels.formula.api import ols #유의미한 판단 상수항 포함
from statsmodels.api import OLS, add_constant #상수함 추가되도록 설계해야함
var_list = ['TV', 'Radio', 'Social_Media']

#(1) LinearRegression: 결측치 제거, x(독립/입력변수)는 2차원으로 입력
q3 = data1.dropna()
lm1 = LinearRegression(fit_intercept=True) # 상수항포함
lm1.fit(q3[var_list],q3['Sales'])

dir(lm1)

lm1.intercept_#:상수

q3_out=pd.Series(lm1.coef_,index = var_list)#:회귀계수
q3_out

q3_out.sort_values(ascending = False).values
#답:[ 3.56256963,  0.00496402, -0.00397039]


```

## ols

```python
#(2) ols
#lm2 = ols(식,데이터셋).fit()

#lm2 = ols(식,데이터셋)
#lm2.fit() #에러발생
#lm3 = lm2.fit() #변수생성
# 식: '종속~(=)x1 + C(x2):범주형으로 변환-레이블별로 더미로 변환 + x3 -1(상수항빼기)'

lm2 = ols('Sales ~ TV + Radio + Social_Media',q3).fit()

form1 = 'Sales~' + '+'.join(var_list) + # '-1'
lm2 = ols(form1,q3).fit()

dir(lm2)
lm2.summary()
lm2.params.drop('Intercept').sort_values(ascending = False)

lm2.params[lm2.pvalues <0.05]

q3[lm2.outlier_test()['bonf(p)']>0.05]
```

## OLS

```python
#(3) OLS: 상수항 미포함된 회귀식 리턴
#OLS(y,x변수).fit()
xx = add_constant(q3[var_list])
lm3 = OLS(q3['Sales'],xx).fit()

lm3.summary()
```



### regression result






![image-20220321113938144](C:\Users\eunwon\AppData\Roaming\Typora\typora-user-images\image-20220321113938144.png)



### R스퀘어 : 데이터의 분산정도- 단일모델에서 사용

표준화된 R스퀘어=> 모델선택(어떤모델이 최적일지/best회귀)

### F 통계량: 회귀선 존재여부

### pvalue : 의사결정- 어떤변수가 영향?

- 기무가설(모집단베이스) :기존이 나음 

- 대립가설: 모집단에 반대되는 가설(표본베이스) :기존보다 나아짐

신뢰수준: 0.95
유의수준:0.05:알파

- 모집단 정보가 잘못주어진경우

- 표본이 극단적으로 선택된경우: 신뢰수준 밖에 위치

유의수준: 기무가설이 맞음에도 기무가설을 기각할 확률 = 알파

p-value = p(F>F0) :내가 택한 F값이 기무가설을 기각할 확률

![image-20220321115438292](C:\Users\eunwon\AppData\Roaming\Typora\typora-user-images\image-20220321115438292.png)

p-value> 0.05 : 기무가설채택하는 영역내에있음=>회귀식이 없음

p-value<0.05 (알파):기무가설 기각 (샘플링잘못해서 틀릴수있음을 알고 의사결정)=> 회귀식 존재



### 잔차분석

yi-y^ : ei(잔차)

- 독립

- 정규분포

- 등분산

=>만족시킬경우 y^이 베스트모델

### t분포:회귀계수를 표준화

모분산 표준편차를 알수없어서 표본에서 추정한값을 사용

t = coef/ std_error

(P>|t|)<0.05: 유의미하다

### 지표

단일지표로 판단은 X

R^2:선형일때만

SSE:데이터길이가같을때만

MSE

RMSE

MAPE

**R-squared**

모형이 데이터에 잘 맞는 정도를 보여주는 지표중 하나이다. R 제곱이라는 뜻으로 위의 데이터에는 0.603으로 표현되는 것을 알 수 있다. 쉽게 말하면 얼마나 선형적인가(a = B0 + B1 * weight)를 표현한 수치라고 할 수 있다. 범위는 0에서 1 사이의 값으로 0이면 모델의 설명력이 전혀 없는 상태이고, 1에 가까울수록 모델이 데이터를 잘 성명해 주는 상태라고 할 수 있다. **보통은 0.4 이상이면 괜찮은 모델이라 할 수 있다.**

 

**No.observations**

위의 결과를 보면 17000개의 데이터 쌍을 가지고 회귀 분석을 하였다는 것을 표현한 것이다

 

**Df Residuals**

전체 관찰 데이서 수에서 회귀 모형의 전체 파라미터의 수를 뺀 값이다.

 

**P>|t| (유의 확률)**

독립변수의 유의 확률로 보통은 독립변수가 95%의 신뢰도를 가져야 유의미하다 판단하고 유의 확률은 0.05보다 작은 값이 산출된다. 즉, 0.05보다 작으면 독립 변수가 종속 변수에 영향을 미치는 것이 유의미하다고 보면 된다.

p-value(유의 확률, significance probability)는 '귀무가설(Null hypothesis)이 맞는다고 가정할 때 얻은 결과보다 극단적인 결과(관측 결과)가 나타날 확률'로 정의됩니다. 일반적으로 p-value < 0.05 혹은 0.01을 기준으로 합니다. 계산된 p-value가 기준값보다 작은 경우 귀무가설을 기각하는 것으로 즉, 극단적으로 귀무가설이 일어날 확률이 매우 낮은 상태를 의미합니다.

 

**Durbin-Watson(더 빈 왓슨, DW검정)**

잔차의 **독립성을 확인**할 수 있는 수치다.

- 0이면 잔차들이 양의 자기 상관을 가진다.
- 2이면 자기 상관이 없는 독립성을 가진다.
- 4이면 잔차들이 음의 자기 상관을 가진다.

 

보통 1.5에서 2.5 사이이면 독립으로 판단하고 회귀 모형이 적합하다는 것을 의미한다. 만약 0이나 4에 가깝다면 잔차들이 자기상관을 가지고 있다는 의미이므로 t, F, R제곱을 실제보다 증가시켜 유의미하지 않은 결과를 유의미한 결과로 왜곡하게 한다. 

 

결론 : R-squeared가 0.4 이상이고, p-value가 0.05 보다 작으므로 유의한 결과가 나왔다고 할 수 있다.
