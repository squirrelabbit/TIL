

# 1. 오차행렬

![image-20220202091419238](C:\Users\eunwon\AppData\Roaming\Typora\typora-user-images\image-20220202091419238.png)

# 2. 정밀도(precision) 재현율(recall)

정밀도:예측 positive(1)중 실츨실체일치  precision_score()

재현율: 실제 positive 중 예측실체 일치   recall_score()

``` 
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,roc_auc_score
```
## 2.1 임계값(Threshold)
재현율 중요지표 (실제 양성중 예측이 맞는)가급적 양성(1)이라고하고 확인 :임계값 down
-ex) 암진단, 금융사기 판별
정밀도 중요지표 (예측 양성중 실제가 맞는)가급적 음성(0)이라하고 확인 : 임계값 up

### - Binazer
Binarizer : 요소들이 기준값보다 큰지 작은지를 알려주는 함수
>요소가 기준값(threshold)과 비교해서,
>-같거나 작으면 0을 반환
>
>-크면 1을 반환
```from sklearn.preprocessing import Binarizer
# Binarizer의 threshold를 1.1로 세팅.
binarizer = Binarizer(threshold=1.1)                     

# array X의 값들이 1.1보다 작거나 같으면 0, 크면 1을 반환한다.
binarizer.fit_transform(X)
```

## 2.2 트레이드 오프관계

```from sklearn.metrics import precision_recall_curve
from sklearn.metrics import precision_recall_curve
```

``` import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

# 정밀도, 재현율 변화 그래프 그리는 코드
def precision_recall_curve_plot(y_test , pred_proba_c1):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    plt.title('Precision and recall by classification threshold')
    
    # threshold 값 X 축의 Scale을 0.1 단위로 변경
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1), 2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()

# 분류 임계값이 변화됨에 따라 정밀도(precision), 재현율(recall) 추이
precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )
```

![](3.평가(evaluation).assets/image-20220202092820599.png)

-> 분류 임계값이 증가하면 정밀도(precision)가 증가한다.



# 3. F1 Score

정밀도와 재현율 결합 지표 but 정밀도 재현율이 한쪽으로 치우치지않을때 높은값을가짐

```from sklearn.metrics import f1_score 
from sklearn.metrics import f1_score 
```

![image-20220202094019953](3.평가(evaluation).assets/image-20220202094019953.png)



# 4. ROC곡선 AUC

> 이진 분류의 예측성능 측정
>
> 머신러닝 이진분류모델 예측성능판단

ROC곡선: FPR(False positive rate) 변화에따른 TPR(재현율)변화

- TPR: TP/(FN+ TP)

- FPR: FP/(FP+TN): 실제 negative중 positive로 잘못 예측

AUC: ROC곡선 아래면적

```from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_auc_score
pred_proba = lr_clf.predict_proba(X_test)[:, 1]
roc_score = roc_auc_score(y_test, pred_proba)
print('ROC AUC 값: {0:.4f}'.format(roc_score))
```

``` # ROC-AUC가 추가된 get_clf_eval 함수 
# : 모델의 평가지표들(오차 행렬, 정확도, 정밀도, 재현율, f1 score, ROC AUC)을 보여준다.
def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    
    # ROC-AUC 추가 
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc), '\n')
