{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"../dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = df.values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[:, 13]\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))  # 입력층\n",
    "                                                       # 은닉층1\n",
    "model.add(Dense(25, activation='relu'))    \n",
    "model.add(Dense(15, activation='relu'))            \n",
    "model.add(Dense(6, activation='relu'))                 # \n",
    "model.add(Dense(1))                                    # 출력층\n",
    "# 선형 회귀는 마지막에 참과 거짓을 구분할 필요가 없음. 출력층에 활성화 함수를 지정할 필요도 없음\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_mse', verbose=1, save_best_only=True)\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_mse', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 195.7872 - mse: 195.7872\n",
      "Epoch 00001: val_mse improved from inf to 97.15369, saving model to ./model/01-97.1537.hdf5\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 104.1232 - mse: 104.1232 - val_loss: 97.1537 - val_mse: 97.1537\n",
      "Epoch 2/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 128.4623 - mse: 128.4623\n",
      "Epoch 00002: val_mse improved from 97.15369 to 83.70543, saving model to ./model/02-83.7054.hdf5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.5013 - mse: 71.5013 - val_loss: 83.7054 - val_mse: 83.7054\n",
      "Epoch 3/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 55.1438 - mse: 55.1438\n",
      "Epoch 00003: val_mse improved from 83.70543 to 74.23959, saving model to ./model/03-74.2396.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.4464 - mse: 72.4464 - val_loss: 74.2396 - val_mse: 74.2396\n",
      "Epoch 4/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 85.4269 - mse: 85.4269\n",
      "Epoch 00004: val_mse improved from 74.23959 to 70.43792, saving model to ./model/04-70.4379.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.8571 - mse: 68.8571 - val_loss: 70.4379 - val_mse: 70.4379\n",
      "Epoch 5/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 98.5695 - mse: 98.5695\n",
      "Epoch 00005: val_mse improved from 70.43792 to 68.26180, saving model to ./model/05-68.2618.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62.3751 - mse: 62.3751 - val_loss: 68.2618 - val_mse: 68.2618\n",
      "Epoch 6/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 55.4344 - mse: 55.4344\n",
      "Epoch 00006: val_mse improved from 68.26180 to 67.29971, saving model to ./model/06-67.2997.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 61.8742 - mse: 61.8742 - val_loss: 67.2997 - val_mse: 67.2997\n",
      "Epoch 7/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 69.6042 - mse: 69.6042\n",
      "Epoch 00007: val_mse improved from 67.29971 to 64.71997, saving model to ./model/07-64.7200.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62.0991 - mse: 62.0991 - val_loss: 64.7200 - val_mse: 64.7200\n",
      "Epoch 8/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 40.5922 - mse: 40.5922\n",
      "Epoch 00008: val_mse did not improve from 64.71997\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.2086 - mse: 60.2086 - val_loss: 64.7660 - val_mse: 64.7660\n",
      "Epoch 9/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 45.2530 - mse: 45.2530\n",
      "Epoch 00009: val_mse improved from 64.71997 to 62.51401, saving model to ./model/09-62.5140.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 59.5520 - mse: 59.5520 - val_loss: 62.5140 - val_mse: 62.5140\n",
      "Epoch 10/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.9128 - mse: 31.9128\n",
      "Epoch 00010: val_mse did not improve from 62.51401\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 57.8483 - mse: 57.8483 - val_loss: 62.8975 - val_mse: 62.8975\n",
      "Epoch 11/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 39.3690 - mse: 39.3690\n",
      "Epoch 00011: val_mse improved from 62.51401 to 61.18912, saving model to ./model/11-61.1891.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.6090 - mse: 57.6090 - val_loss: 61.1891 - val_mse: 61.1891\n",
      "Epoch 12/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 32.1511 - mse: 32.1511\n",
      "Epoch 00012: val_mse improved from 61.18912 to 60.54584, saving model to ./model/12-60.5458.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.8138 - mse: 56.8138 - val_loss: 60.5458 - val_mse: 60.5458\n",
      "Epoch 13/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 40.2235 - mse: 40.2235\n",
      "Epoch 00013: val_mse improved from 60.54584 to 59.63909, saving model to ./model/13-59.6391.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.7536 - mse: 56.7536 - val_loss: 59.6391 - val_mse: 59.6391\n",
      "Epoch 14/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 53.8662 - mse: 53.8662\n",
      "Epoch 00014: val_mse did not improve from 59.63909\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 55.6871 - mse: 55.6871 - val_loss: 60.3827 - val_mse: 60.3827\n",
      "Epoch 15/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 74.4830 - mse: 74.4830\n",
      "Epoch 00015: val_mse improved from 59.63909 to 59.61679, saving model to ./model/15-59.6168.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 54.7297 - mse: 54.7297 - val_loss: 59.6168 - val_mse: 59.6168\n",
      "Epoch 16/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 67.0740 - mse: 67.0740\n",
      "Epoch 00016: val_mse improved from 59.61679 to 59.31781, saving model to ./model/16-59.3178.hdf5\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 55.1262 - mse: 55.1262 - val_loss: 59.3178 - val_mse: 59.3178\n",
      "Epoch 17/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.3857 - mse: 24.3857\n",
      "Epoch 00017: val_mse improved from 59.31781 to 58.21626, saving model to ./model/17-58.2163.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 55.5952 - mse: 55.5952 - val_loss: 58.2163 - val_mse: 58.2163\n",
      "Epoch 18/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 53.0615 - mse: 53.0615\n",
      "Epoch 00018: val_mse improved from 58.21626 to 56.97128, saving model to ./model/18-56.9713.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 54.4141 - mse: 54.4141 - val_loss: 56.9713 - val_mse: 56.9713\n",
      "Epoch 19/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 57.3220 - mse: 57.3220\n",
      "Epoch 00019: val_mse did not improve from 56.97128\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.2190 - mse: 53.2190 - val_loss: 58.1353 - val_mse: 58.1353\n",
      "Epoch 20/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.7763 - mse: 31.7763\n",
      "Epoch 00020: val_mse improved from 56.97128 to 56.08252, saving model to ./model/20-56.0825.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 54.1392 - mse: 54.1392 - val_loss: 56.0825 - val_mse: 56.0825\n",
      "Epoch 21/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.9332 - mse: 23.9332\n",
      "Epoch 00021: val_mse did not improve from 56.08252\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.0103 - mse: 53.0103 - val_loss: 56.2587 - val_mse: 56.2587\n",
      "Epoch 22/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 117.2478 - mse: 117.2478\n",
      "Epoch 00022: val_mse did not improve from 56.08252\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 51.6794 - mse: 51.6794 - val_loss: 56.2543 - val_mse: 56.2543\n",
      "Epoch 23/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.2721 - mse: 20.2721\n",
      "Epoch 00023: val_mse did not improve from 56.08252\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 53.6016 - mse: 53.6016 - val_loss: 61.6374 - val_mse: 61.6374\n",
      "Epoch 24/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 70.7773 - mse: 70.7773\n",
      "Epoch 00024: val_mse did not improve from 56.08252\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 55.9696 - mse: 55.9696 - val_loss: 56.9567 - val_mse: 56.9567\n",
      "Epoch 25/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 45.2810 - mse: 45.2810\n",
      "Epoch 00025: val_mse did not improve from 56.08252\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 52.2132 - mse: 52.2132 - val_loss: 56.8392 - val_mse: 56.8392\n",
      "Epoch 26/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 54.6605 - mse: 54.6605\n",
      "Epoch 00026: val_mse improved from 56.08252 to 53.52123, saving model to ./model/26-53.5212.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50.1848 - mse: 50.1848 - val_loss: 53.5212 - val_mse: 53.5212\n",
      "Epoch 27/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 64.4497 - mse: 64.4497\n",
      "Epoch 00027: val_mse improved from 53.52123 to 53.39962, saving model to ./model/27-53.3996.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49.6235 - mse: 49.6235 - val_loss: 53.3996 - val_mse: 53.3996\n",
      "Epoch 28/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 59.3123 - mse: 59.3123\n",
      "Epoch 00028: val_mse improved from 53.39962 to 53.11743, saving model to ./model/28-53.1174.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49.1574 - mse: 49.1574 - val_loss: 53.1174 - val_mse: 53.1174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 29.6856 - mse: 29.6856\n",
      "Epoch 00029: val_mse did not improve from 53.11743\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 49.2259 - mse: 49.2259 - val_loss: 53.9309 - val_mse: 53.9309\n",
      "Epoch 30/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 47.0658 - mse: 47.0658\n",
      "Epoch 00030: val_mse improved from 53.11743 to 52.16995, saving model to ./model/30-52.1700.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48.3040 - mse: 48.3040 - val_loss: 52.1700 - val_mse: 52.1700\n",
      "Epoch 31/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 54.9542 - mse: 54.9542\n",
      "Epoch 00031: val_mse improved from 52.16995 to 51.72659, saving model to ./model/31-51.7266.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48.2122 - mse: 48.2122 - val_loss: 51.7266 - val_mse: 51.7266\n",
      "Epoch 32/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 44.2684 - mse: 44.2684\n",
      "Epoch 00032: val_mse did not improve from 51.72659\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47.9317 - mse: 47.9317 - val_loss: 51.9293 - val_mse: 51.9293\n",
      "Epoch 33/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 56.4794 - mse: 56.4794\n",
      "Epoch 00033: val_mse did not improve from 51.72659\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.9575 - mse: 46.9575 - val_loss: 52.1765 - val_mse: 52.1765\n",
      "Epoch 34/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 54.4789 - mse: 54.4789\n",
      "Epoch 00034: val_mse improved from 51.72659 to 50.58764, saving model to ./model/34-50.5876.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 46.6604 - mse: 46.6604 - val_loss: 50.5876 - val_mse: 50.5876\n",
      "Epoch 35/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 105.9020 - mse: 105.9020\n",
      "Epoch 00035: val_mse improved from 50.58764 to 49.63727, saving model to ./model/35-49.6373.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 46.4041 - mse: 46.4041 - val_loss: 49.6373 - val_mse: 49.6373\n",
      "Epoch 36/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 49.4746 - mse: 49.4746\n",
      "Epoch 00036: val_mse improved from 49.63727 to 49.35117, saving model to ./model/36-49.3512.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 45.8019 - mse: 45.8019 - val_loss: 49.3512 - val_mse: 49.3512\n",
      "Epoch 37/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 32.5056 - mse: 32.5056\n",
      "Epoch 00037: val_mse improved from 49.35117 to 49.24273, saving model to ./model/37-49.2427.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.7469 - mse: 45.7469 - val_loss: 49.2427 - val_mse: 49.2427\n",
      "Epoch 38/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 56.7863 - mse: 56.7863\n",
      "Epoch 00038: val_mse improved from 49.24273 to 49.24125, saving model to ./model/38-49.2412.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 44.8757 - mse: 44.8757 - val_loss: 49.2412 - val_mse: 49.2412\n",
      "Epoch 39/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 47.0208 - mse: 47.0208\n",
      "Epoch 00039: val_mse improved from 49.24125 to 48.48829, saving model to ./model/39-48.4883.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.8064 - mse: 44.8064 - val_loss: 48.4883 - val_mse: 48.4883\n",
      "Epoch 40/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 48.9037 - mse: 48.9037\n",
      "Epoch 00040: val_mse did not improve from 48.48829\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44.2058 - mse: 44.2058 - val_loss: 50.9072 - val_mse: 50.9072\n",
      "Epoch 41/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 38.2027 - mse: 38.2027\n",
      "Epoch 00041: val_mse improved from 48.48829 to 47.18350, saving model to ./model/41-47.1835.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 44.6878 - mse: 44.6878 - val_loss: 47.1835 - val_mse: 47.1835\n",
      "Epoch 42/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.8392 - mse: 23.8392\n",
      "Epoch 00042: val_mse did not improve from 47.18350\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.8195 - mse: 42.8195 - val_loss: 47.7453 - val_mse: 47.7453\n",
      "Epoch 43/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.9595 - mse: 31.9595\n",
      "Epoch 00043: val_mse did not improve from 47.18350\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.2946 - mse: 42.2946 - val_loss: 47.3958 - val_mse: 47.3958\n",
      "Epoch 44/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.5026 - mse: 31.5026\n",
      "Epoch 00044: val_mse improved from 47.18350 to 46.16331, saving model to ./model/44-46.1633.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 41.8135 - mse: 41.8135 - val_loss: 46.1633 - val_mse: 46.1633\n",
      "Epoch 45/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.2240 - mse: 30.2240\n",
      "Epoch 00045: val_mse did not improve from 46.16331\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.6231 - mse: 41.6231 - val_loss: 49.3272 - val_mse: 49.3272\n",
      "Epoch 46/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 29.3116 - mse: 29.3116\n",
      "Epoch 00046: val_mse did not improve from 46.16331\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.6126 - mse: 41.6126 - val_loss: 46.2426 - val_mse: 46.2426\n",
      "Epoch 47/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 76.5347 - mse: 76.5347\n",
      "Epoch 00047: val_mse did not improve from 46.16331\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 41.2630 - mse: 41.2630 - val_loss: 46.2434 - val_mse: 46.2434\n",
      "Epoch 48/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 45.4909 - mse: 45.4909\n",
      "Epoch 00048: val_mse improved from 46.16331 to 45.24476, saving model to ./model/48-45.2448.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 40.0975 - mse: 40.0975 - val_loss: 45.2448 - val_mse: 45.2448\n",
      "Epoch 49/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 51.3915 - mse: 51.3915\n",
      "Epoch 00049: val_mse improved from 45.24476 to 44.72632, saving model to ./model/49-44.7263.hdf5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.1980 - mse: 40.1980 - val_loss: 44.7263 - val_mse: 44.7263\n",
      "Epoch 50/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.4854 - mse: 14.4854\n",
      "Epoch 00050: val_mse improved from 44.72632 to 44.10436, saving model to ./model/50-44.1044.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 39.1503 - mse: 39.1503 - val_loss: 44.1044 - val_mse: 44.1044\n",
      "Epoch 51/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 71.3244 - mse: 71.3244\n",
      "Epoch 00051: val_mse improved from 44.10436 to 43.68372, saving model to ./model/51-43.6837.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.2634 - mse: 38.2634 - val_loss: 43.6837 - val_mse: 43.6837\n",
      "Epoch 52/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 28.8617 - mse: 28.8617\n",
      "Epoch 00052: val_mse did not improve from 43.68372\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 38.2803 - mse: 38.2803 - val_loss: 45.2843 - val_mse: 45.2843\n",
      "Epoch 53/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 27.6506 - mse: 27.6506\n",
      "Epoch 00053: val_mse did not improve from 43.68372\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 39.1161 - mse: 39.1161 - val_loss: 48.0015 - val_mse: 48.0015\n",
      "Epoch 54/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 36.9803 - mse: 36.9803\n",
      "Epoch 00054: val_mse did not improve from 43.68372\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.4899 - mse: 40.4899 - val_loss: 52.1534 - val_mse: 52.1534\n",
      "Epoch 55/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 67.3324 - mse: 67.3324\n",
      "Epoch 00055: val_mse improved from 43.68372 to 42.96330, saving model to ./model/55-42.9633.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 43.0327 - mse: 43.0327 - val_loss: 42.9633 - val_mse: 42.9633\n",
      "Epoch 56/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.2721 - mse: 24.2721\n",
      "Epoch 00056: val_mse did not improve from 42.96330\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.8008 - mse: 40.8008 - val_loss: 55.7640 - val_mse: 55.7640\n",
      "Epoch 57/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 32.5017 - mse: 32.5017\n",
      "Epoch 00057: val_mse improved from 42.96330 to 42.71935, saving model to ./model/57-42.7193.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 44.8648 - mse: 44.8648 - val_loss: 42.7193 - val_mse: 42.7193\n",
      "Epoch 58/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 76.0182 - mse: 76.0182\n",
      "Epoch 00058: val_mse did not improve from 42.71935\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.6334 - mse: 42.6334 - val_loss: 47.5655 - val_mse: 47.5655\n",
      "Epoch 59/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.9757 - mse: 21.9757\n",
      "Epoch 00059: val_mse did not improve from 42.71935\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 40.0548 - mse: 40.0548 - val_loss: 49.0849 - val_mse: 49.0849\n",
      "Epoch 60/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 48.6586 - mse: 48.6586\n",
      "Epoch 00060: val_mse improved from 42.71935 to 42.06163, saving model to ./model/60-42.0616.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.1021 - mse: 38.1021 - val_loss: 42.0616 - val_mse: 42.0616\n",
      "Epoch 61/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 75.7612 - mse: 75.7612\n",
      "Epoch 00061: val_mse improved from 42.06163 to 41.05302, saving model to ./model/61-41.0530.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35.4739 - mse: 35.4739 - val_loss: 41.0530 - val_mse: 41.0530\n",
      "Epoch 62/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.6908 - mse: 31.6908\n",
      "Epoch 00062: val_mse improved from 41.05302 to 40.34473, saving model to ./model/62-40.3447.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36.5817 - mse: 36.5817 - val_loss: 40.3447 - val_mse: 40.3447\n",
      "Epoch 63/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 45.3936 - mse: 45.3936\n",
      "Epoch 00063: val_mse did not improve from 40.34473\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.7376 - mse: 35.7376 - val_loss: 40.3838 - val_mse: 40.3838\n",
      "Epoch 64/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.9113 - mse: 24.9113\n",
      "Epoch 00064: val_mse did not improve from 40.34473\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.0932 - mse: 34.0932 - val_loss: 40.8114 - val_mse: 40.8114\n",
      "Epoch 65/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 41.2654 - mse: 41.2654\n",
      "Epoch 00065: val_mse improved from 40.34473 to 39.94985, saving model to ./model/65-39.9499.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34.9102 - mse: 34.9102 - val_loss: 39.9499 - val_mse: 39.9499\n",
      "Epoch 66/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 35.6608 - mse: 35.6608\n",
      "Epoch 00066: val_mse did not improve from 39.94985\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.8785 - mse: 33.8785 - val_loss: 40.1261 - val_mse: 40.1261\n",
      "Epoch 67/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 28.4274 - mse: 28.4274\n",
      "Epoch 00067: val_mse did not improve from 39.94985\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.5640 - mse: 34.5640 - val_loss: 43.8348 - val_mse: 43.8348\n",
      "Epoch 68/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 47.7558 - mse: 47.7558\n",
      "Epoch 00068: val_mse did not improve from 39.94985\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.3314 - mse: 35.3314 - val_loss: 41.6212 - val_mse: 41.6212\n",
      "Epoch 69/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.7095 - mse: 15.7095\n",
      "Epoch 00069: val_mse did not improve from 39.94985\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.6146 - mse: 34.6146 - val_loss: 40.2098 - val_mse: 40.2098\n",
      "Epoch 70/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 64.7110 - mse: 64.7110\n",
      "Epoch 00070: val_mse improved from 39.94985 to 39.69921, saving model to ./model/70-39.6992.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34.4930 - mse: 34.4930 - val_loss: 39.6992 - val_mse: 39.6992\n",
      "Epoch 71/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 55.9695 - mse: 55.9695\n",
      "Epoch 00071: val_mse did not improve from 39.69921\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.5696 - mse: 34.5696 - val_loss: 40.1578 - val_mse: 40.1578\n",
      "Epoch 72/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 42.9704 - mse: 42.9704\n",
      "Epoch 00072: val_mse improved from 39.69921 to 39.35952, saving model to ./model/72-39.3595.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.9038 - mse: 32.9038 - val_loss: 39.3595 - val_mse: 39.3595\n",
      "Epoch 73/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 47.7317 - mse: 47.7317\n",
      "Epoch 00073: val_mse improved from 39.35952 to 38.95345, saving model to ./model/73-38.9535.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.2044 - mse: 32.2044 - val_loss: 38.9535 - val_mse: 38.9535\n",
      "Epoch 74/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 37.6425 - mse: 37.6425\n",
      "Epoch 00074: val_mse improved from 38.95345 to 38.04953, saving model to ./model/74-38.0495.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.6012 - mse: 32.6012 - val_loss: 38.0495 - val_mse: 38.0495\n",
      "Epoch 75/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.4132 - mse: 19.4132\n",
      "Epoch 00075: val_mse did not improve from 38.04953\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.0888 - mse: 31.0888 - val_loss: 38.9528 - val_mse: 38.9528\n",
      "Epoch 76/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 56.2973 - mse: 56.2973\n",
      "Epoch 00076: val_mse improved from 38.04953 to 38.00887, saving model to ./model/76-38.0089.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 31.8714 - mse: 31.8714 - val_loss: 38.0089 - val_mse: 38.0089\n",
      "Epoch 77/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.7367 - mse: 16.7367\n",
      "Epoch 00077: val_mse did not improve from 38.00887\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.2291 - mse: 31.2291 - val_loss: 38.8533 - val_mse: 38.8533\n",
      "Epoch 78/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.2144 - mse: 30.2144\n",
      "Epoch 00078: val_mse improved from 38.00887 to 37.74681, saving model to ./model/78-37.7468.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 30.6328 - mse: 30.6328 - val_loss: 37.7468 - val_mse: 37.7468\n",
      "Epoch 79/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 43.6149 - mse: 43.6149\n",
      "Epoch 00079: val_mse did not improve from 37.74681\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9952 - mse: 30.9952 - val_loss: 37.7973 - val_mse: 37.7973\n",
      "Epoch 80/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 40.3773 - mse: 40.3773\n",
      "Epoch 00080: val_mse improved from 37.74681 to 37.44075, saving model to ./model/80-37.4408.hdf5\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 30.7157 - mse: 30.7157 - val_loss: 37.4408 - val_mse: 37.4408\n",
      "Epoch 81/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.8466 - mse: 23.8466\n",
      "Epoch 00081: val_mse did not improve from 37.44075\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.1895 - mse: 31.1895 - val_loss: 39.8060 - val_mse: 39.8060\n",
      "Epoch 82/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 77.5776 - mse: 77.5776\n",
      "Epoch 00082: val_mse did not improve from 37.44075\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.7978 - mse: 32.7978 - val_loss: 39.0555 - val_mse: 39.0555\n",
      "Epoch 83/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.4891 - mse: 33.4891\n",
      "Epoch 00083: val_mse improved from 37.44075 to 37.21325, saving model to ./model/83-37.2132.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.0247 - mse: 32.0247 - val_loss: 37.2132 - val_mse: 37.2132\n",
      "Epoch 84/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.6190 - mse: 14.6190\n",
      "Epoch 00084: val_mse did not improve from 37.21325\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.3601 - mse: 34.3601 - val_loss: 51.0894 - val_mse: 51.0894\n",
      "Epoch 85/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 38.7850 - mse: 38.7850\n",
      "Epoch 00085: val_mse did not improve from 37.21325\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.2285 - mse: 32.2285 - val_loss: 37.7884 - val_mse: 37.7884\n",
      "Epoch 86/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 29.5360 - mse: 29.5360\n",
      "Epoch 00086: val_mse improved from 37.21325 to 36.95068, saving model to ./model/86-36.9507.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 29.5763 - mse: 29.5763 - val_loss: 36.9507 - val_mse: 36.9507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.8738 - mse: 15.8738\n",
      "Epoch 00087: val_mse did not improve from 36.95068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.9469 - mse: 28.9469 - val_loss: 38.2579 - val_mse: 38.2579\n",
      "Epoch 88/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.8562 - mse: 33.8562\n",
      "Epoch 00088: val_mse did not improve from 36.95068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.7250 - mse: 28.7250 - val_loss: 37.0510 - val_mse: 37.0510\n",
      "Epoch 89/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 38.6986 - mse: 38.6986\n",
      "Epoch 00089: val_mse improved from 36.95068 to 35.91000, saving model to ./model/89-35.9100.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 29.4840 - mse: 29.4840 - val_loss: 35.9100 - val_mse: 35.9100\n",
      "Epoch 90/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.4455 - mse: 21.4455\n",
      "Epoch 00090: val_mse did not improve from 35.91000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4262 - mse: 29.4262 - val_loss: 42.6788 - val_mse: 42.6788\n",
      "Epoch 91/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.8065 - mse: 26.8065\n",
      "Epoch 00091: val_mse improved from 35.91000 to 35.84900, saving model to ./model/91-35.8490.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30.6646 - mse: 30.6646 - val_loss: 35.8490 - val_mse: 35.8490\n",
      "Epoch 92/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 27.2873 - mse: 27.2873\n",
      "Epoch 00092: val_mse improved from 35.84900 to 35.60357, saving model to ./model/92-35.6036.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 28.7237 - mse: 28.7237 - val_loss: 35.6036 - val_mse: 35.6036\n",
      "Epoch 93/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1026 - mse: 11.1026\n",
      "Epoch 00093: val_mse did not improve from 35.60357\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.0662 - mse: 31.0662 - val_loss: 38.9967 - val_mse: 38.9967\n",
      "Epoch 94/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 38.5372 - mse: 38.5372\n",
      "Epoch 00094: val_mse did not improve from 35.60357\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4617 - mse: 28.4617 - val_loss: 36.7302 - val_mse: 36.7302\n",
      "Epoch 95/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 25.8264 - mse: 25.8264\n",
      "Epoch 00095: val_mse did not improve from 35.60357\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1272 - mse: 30.1272 - val_loss: 35.6119 - val_mse: 35.6119\n",
      "Epoch 96/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.9204 - mse: 10.9204\n",
      "Epoch 00096: val_mse did not improve from 35.60357\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.2445 - mse: 27.2445 - val_loss: 36.8502 - val_mse: 36.8502\n",
      "Epoch 97/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.4569 - mse: 22.4569\n",
      "Epoch 00097: val_mse improved from 35.60357 to 35.41987, saving model to ./model/97-35.4199.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.6141 - mse: 27.6141 - val_loss: 35.4199 - val_mse: 35.4199\n",
      "Epoch 98/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.5895 - mse: 20.5895\n",
      "Epoch 00098: val_mse did not improve from 35.41987\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1610 - mse: 28.1610 - val_loss: 35.4799 - val_mse: 35.4799\n",
      "Epoch 99/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 34.6285 - mse: 34.6285\n",
      "Epoch 00099: val_mse did not improve from 35.41987\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8162 - mse: 27.8162 - val_loss: 36.1232 - val_mse: 36.1232\n",
      "Epoch 100/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.8538 - mse: 21.8538\n",
      "Epoch 00100: val_mse did not improve from 35.41987\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8153 - mse: 28.8153 - val_loss: 35.4261 - val_mse: 35.4261\n",
      "Epoch 101/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.7023 - mse: 14.7023\n",
      "Epoch 00101: val_mse did not improve from 35.41987\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.9132 - mse: 26.9132 - val_loss: 35.6075 - val_mse: 35.6075\n",
      "Epoch 102/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.7074 - mse: 26.7074\n",
      "Epoch 00102: val_mse improved from 35.41987 to 35.14793, saving model to ./model/102-35.1479.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.0751 - mse: 27.0751 - val_loss: 35.1479 - val_mse: 35.1479\n",
      "Epoch 103/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7467 - mse: 12.7467\n",
      "Epoch 00103: val_mse improved from 35.14793 to 34.83060, saving model to ./model/103-34.8306.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.7486 - mse: 27.7486 - val_loss: 34.8306 - val_mse: 34.8306\n",
      "Epoch 104/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.1592 - mse: 33.1592\n",
      "Epoch 00104: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.9798 - mse: 28.9798 - val_loss: 43.8051 - val_mse: 43.8051\n",
      "Epoch 105/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.0915 - mse: 26.0915\n",
      "Epoch 00105: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36.1066 - mse: 36.1066 - val_loss: 37.7663 - val_mse: 37.7663\n",
      "Epoch 106/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.2618 - mse: 21.2618\n",
      "Epoch 00106: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.8635 - mse: 31.8635 - val_loss: 53.3137 - val_mse: 53.3137\n",
      "Epoch 107/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 38.5723 - mse: 38.5723\n",
      "Epoch 00107: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.6951 - mse: 32.6951 - val_loss: 41.0326 - val_mse: 41.0326\n",
      "Epoch 108/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 53.2360 - mse: 53.2360\n",
      "Epoch 00108: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.7954 - mse: 32.7954 - val_loss: 39.6852 - val_mse: 39.6852\n",
      "Epoch 109/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 40.5865 - mse: 40.5865\n",
      "Epoch 00109: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9070 - mse: 30.9070 - val_loss: 35.1086 - val_mse: 35.1086\n",
      "Epoch 110/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.1815 - mse: 16.1815\n",
      "Epoch 00110: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.0841 - mse: 30.0841 - val_loss: 42.8065 - val_mse: 42.8065\n",
      "Epoch 111/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.9529 - mse: 26.9529\n",
      "Epoch 00111: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4005 - mse: 29.4005 - val_loss: 39.0025 - val_mse: 39.0025\n",
      "Epoch 112/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.6365 - mse: 31.6365\n",
      "Epoch 00112: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.8930 - mse: 30.8930 - val_loss: 36.5308 - val_mse: 36.5308\n",
      "Epoch 113/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.0024 - mse: 33.0024\n",
      "Epoch 00113: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4820 - mse: 28.4820 - val_loss: 35.9345 - val_mse: 35.9345\n",
      "Epoch 114/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.7381 - mse: 17.7381\n",
      "Epoch 00114: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.3597 - mse: 29.3597 - val_loss: 42.1300 - val_mse: 42.1300\n",
      "Epoch 115/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 27.5385 - mse: 27.5385\n",
      "Epoch 00115: val_mse did not improve from 34.83060\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1068 - mse: 30.1068 - val_loss: 40.0415 - val_mse: 40.0415\n",
      "Epoch 116/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 28.7149 - mse: 28.7149\n",
      "Epoch 00116: val_mse improved from 34.83060 to 33.93381, saving model to ./model/116-33.9338.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 28.7006 - mse: 28.7006 - val_loss: 33.9338 - val_mse: 33.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.2740 - mse: 24.2740\n",
      "Epoch 00117: val_mse did not improve from 33.93381\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.9468 - mse: 24.9468 - val_loss: 35.2689 - val_mse: 35.2689\n",
      "Epoch 118/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.8109 - mse: 19.8109\n",
      "Epoch 00118: val_mse did not improve from 33.93381\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.8141 - mse: 25.8141 - val_loss: 36.5477 - val_mse: 36.5477\n",
      "Epoch 119/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.1032 - mse: 19.1032\n",
      "Epoch 00119: val_mse improved from 33.93381 to 33.76304, saving model to ./model/119-33.7630.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.7374 - mse: 26.7374 - val_loss: 33.7630 - val_mse: 33.7630\n",
      "Epoch 120/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 65.1730 - mse: 65.1730\n",
      "Epoch 00120: val_mse did not improve from 33.76304\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4137 - mse: 29.4137 - val_loss: 35.6715 - val_mse: 35.6715\n",
      "Epoch 121/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.2966 - mse: 18.2966\n",
      "Epoch 00121: val_mse did not improve from 33.76304\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.5125 - mse: 25.5125 - val_loss: 34.4062 - val_mse: 34.4062\n",
      "Epoch 122/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 28.5979 - mse: 28.5979\n",
      "Epoch 00122: val_mse did not improve from 33.76304\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.9106 - mse: 25.9106 - val_loss: 34.5429 - val_mse: 34.5429\n",
      "Epoch 123/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.6298 - mse: 18.6298\n",
      "Epoch 00123: val_mse did not improve from 33.76304\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.5775 - mse: 25.5775 - val_loss: 37.5213 - val_mse: 37.5213\n",
      "Epoch 124/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 39.5545 - mse: 39.5545\n",
      "Epoch 00124: val_mse improved from 33.76304 to 33.43081, saving model to ./model/124-33.4308.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.5300 - mse: 25.5300 - val_loss: 33.4308 - val_mse: 33.4308\n",
      "Epoch 125/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 40.8770 - mse: 40.8770\n",
      "Epoch 00125: val_mse improved from 33.43081 to 33.33466, saving model to ./model/125-33.3347.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.0105 - mse: 26.0105 - val_loss: 33.3347 - val_mse: 33.3347\n",
      "Epoch 126/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.2530 - mse: 33.2530\n",
      "Epoch 00126: val_mse improved from 33.33466 to 33.00096, saving model to ./model/126-33.0010.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.0114 - mse: 25.0114 - val_loss: 33.0010 - val_mse: 33.0010\n",
      "Epoch 127/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2021 - mse: 13.2021\n",
      "Epoch 00127: val_mse did not improve from 33.00096\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.6721 - mse: 24.6721 - val_loss: 33.0717 - val_mse: 33.0717\n",
      "Epoch 128/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.4518 - mse: 31.4518\n",
      "Epoch 00128: val_mse improved from 33.00096 to 32.71337, saving model to ./model/128-32.7134.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.7550 - mse: 24.7550 - val_loss: 32.7134 - val_mse: 32.7134\n",
      "Epoch 129/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.6912 - mse: 16.6912\n",
      "Epoch 00129: val_mse did not improve from 32.71337\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.9474 - mse: 23.9474 - val_loss: 33.1488 - val_mse: 33.1488\n",
      "Epoch 130/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 28.5490 - mse: 28.5490\n",
      "Epoch 00130: val_mse did not improve from 32.71337\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.2841 - mse: 24.2841 - val_loss: 34.2978 - val_mse: 34.2978\n",
      "Epoch 131/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 27.7484 - mse: 27.7484\n",
      "Epoch 00131: val_mse did not improve from 32.71337\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.5410 - mse: 24.5410 - val_loss: 35.1691 - val_mse: 35.1691\n",
      "Epoch 132/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.5176 - mse: 13.5176\n",
      "Epoch 00132: val_mse improved from 32.71337 to 32.34291, saving model to ./model/132-32.3429.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.2766 - mse: 24.2766 - val_loss: 32.3429 - val_mse: 32.3429\n",
      "Epoch 133/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.9570 - mse: 26.9570\n",
      "Epoch 00133: val_mse did not improve from 32.34291\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.6399 - mse: 24.6399 - val_loss: 40.2383 - val_mse: 40.2383\n",
      "Epoch 134/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 36.5142 - mse: 36.5142\n",
      "Epoch 00134: val_mse did not improve from 32.34291\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.1793 - mse: 25.1793 - val_loss: 32.8359 - val_mse: 32.8359\n",
      "Epoch 135/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.7232 - mse: 17.7232\n",
      "Epoch 00135: val_mse improved from 32.34291 to 31.84586, saving model to ./model/135-31.8459.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.0645 - mse: 23.0645 - val_loss: 31.8459 - val_mse: 31.8459\n",
      "Epoch 136/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.6184 - mse: 11.6184\n",
      "Epoch 00136: val_mse did not improve from 31.84586\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.3329 - mse: 24.3329 - val_loss: 34.4934 - val_mse: 34.4934\n",
      "Epoch 137/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.7873 - mse: 11.7873\n",
      "Epoch 00137: val_mse did not improve from 31.84586\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.2767 - mse: 24.2767 - val_loss: 37.9337 - val_mse: 37.9337\n",
      "Epoch 138/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.9309 - mse: 33.9309\n",
      "Epoch 00138: val_mse improved from 31.84586 to 31.08545, saving model to ./model/138-31.0854.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.3048 - mse: 25.3048 - val_loss: 31.0854 - val_mse: 31.0854\n",
      "Epoch 139/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.8773 - mse: 16.8773\n",
      "Epoch 00139: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.0587 - mse: 24.0587 - val_loss: 34.9851 - val_mse: 34.9851\n",
      "Epoch 140/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.8202 - mse: 16.8202\n",
      "Epoch 00140: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.0370 - mse: 26.0370 - val_loss: 31.7326 - val_mse: 31.7326\n",
      "Epoch 141/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 35.3092 - mse: 35.3092\n",
      "Epoch 00141: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.5004 - mse: 22.5004 - val_loss: 33.5212 - val_mse: 33.5212\n",
      "Epoch 142/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.7096 - mse: 24.7096\n",
      "Epoch 00142: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.9046 - mse: 25.9046 - val_loss: 31.1627 - val_mse: 31.1627\n",
      "Epoch 143/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.6342 - mse: 11.6342\n",
      "Epoch 00143: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.3604 - mse: 23.3604 - val_loss: 33.8427 - val_mse: 33.8427\n",
      "Epoch 144/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.1576 - mse: 17.1576\n",
      "Epoch 00144: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.1889 - mse: 23.1889 - val_loss: 32.9507 - val_mse: 32.9507\n",
      "Epoch 145/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.3121 - mse: 19.3121\n",
      "Epoch 00145: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.3201 - mse: 23.3201 - val_loss: 34.7232 - val_mse: 34.7232\n",
      "Epoch 146/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 41.1272 - mse: 41.1272\n",
      "Epoch 00146: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.2768 - mse: 24.2768 - val_loss: 34.4680 - val_mse: 34.4680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.9626 - mse: 30.9626\n",
      "Epoch 00147: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.3100 - mse: 26.3100 - val_loss: 39.1069 - val_mse: 39.1069\n",
      "Epoch 148/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.8163 - mse: 20.8163\n",
      "Epoch 00148: val_mse did not improve from 31.08545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.5708 - mse: 25.5708 - val_loss: 32.0055 - val_mse: 32.0055\n",
      "Epoch 149/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.0243 - mse: 16.0243\n",
      "Epoch 00149: val_mse improved from 31.08545 to 30.97035, saving model to ./model/149-30.9704.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.3541 - mse: 25.3541 - val_loss: 30.9704 - val_mse: 30.9704\n",
      "Epoch 150/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.8960 - mse: 13.8960\n",
      "Epoch 00150: val_mse did not improve from 30.97035\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.9633 - mse: 21.9633 - val_loss: 33.5661 - val_mse: 33.5661\n",
      "Epoch 151/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.7633 - mse: 24.7633\n",
      "Epoch 00151: val_mse did not improve from 30.97035\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3460 - mse: 21.3460 - val_loss: 32.3138 - val_mse: 32.3138\n",
      "Epoch 152/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 36.9319 - mse: 36.9319\n",
      "Epoch 00152: val_mse did not improve from 30.97035\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.7950 - mse: 20.7950 - val_loss: 39.9485 - val_mse: 39.9485\n",
      "Epoch 153/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.1169 - mse: 19.1169\n",
      "Epoch 00153: val_mse did not improve from 30.97035\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.2891 - mse: 22.2891 - val_loss: 30.9742 - val_mse: 30.9742\n",
      "Epoch 154/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.4005 - mse: 23.4005\n",
      "Epoch 00154: val_mse improved from 30.97035 to 29.78351, saving model to ./model/154-29.7835.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.8552 - mse: 21.8552 - val_loss: 29.7835 - val_mse: 29.7835\n",
      "Epoch 155/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.9421 - mse: 15.9421\n",
      "Epoch 00155: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.3146 - mse: 23.3146 - val_loss: 31.9402 - val_mse: 31.9402\n",
      "Epoch 156/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.3233 - mse: 17.3233\n",
      "Epoch 00156: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.1309 - mse: 28.1309 - val_loss: 43.2766 - val_mse: 43.2766\n",
      "Epoch 157/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.5846 - mse: 30.5846\n",
      "Epoch 00157: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.0389 - mse: 26.0389 - val_loss: 30.8187 - val_mse: 30.8187\n",
      "Epoch 158/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.2696 - mse: 26.2696\n",
      "Epoch 00158: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.1227 - mse: 24.1227 - val_loss: 32.8435 - val_mse: 32.8435\n",
      "Epoch 159/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.8111 - mse: 16.8111\n",
      "Epoch 00159: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3422 - mse: 21.3422 - val_loss: 30.3400 - val_mse: 30.3400\n",
      "Epoch 160/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.8279 - mse: 14.8279\n",
      "Epoch 00160: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3437 - mse: 21.3437 - val_loss: 31.2405 - val_mse: 31.2405\n",
      "Epoch 161/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.8019 - mse: 24.8019\n",
      "Epoch 00161: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.9729 - mse: 20.9729 - val_loss: 30.2361 - val_mse: 30.2361\n",
      "Epoch 162/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.4210 - mse: 15.4210\n",
      "Epoch 00162: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.0413 - mse: 21.0413 - val_loss: 30.8545 - val_mse: 30.8545\n",
      "Epoch 163/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.7170 - mse: 21.7170\n",
      "Epoch 00163: val_mse did not improve from 29.78351\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.0410 - mse: 21.0410 - val_loss: 31.4979 - val_mse: 31.4979\n",
      "Epoch 164/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.3570 - mse: 14.3570\n",
      "Epoch 00164: val_mse improved from 29.78351 to 29.48114, saving model to ./model/164-29.4811.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.1195 - mse: 21.1195 - val_loss: 29.4811 - val_mse: 29.4811\n",
      "Epoch 165/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.2244 - mse: 18.2244\n",
      "Epoch 00165: val_mse improved from 29.48114 to 28.64565, saving model to ./model/165-28.6456.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.3281 - mse: 21.3281 - val_loss: 28.6456 - val_mse: 28.6456\n",
      "Epoch 166/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.0170 - mse: 23.0170\n",
      "Epoch 00166: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.9799 - mse: 19.9799 - val_loss: 33.1759 - val_mse: 33.1759\n",
      "Epoch 167/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.7066 - mse: 19.7066\n",
      "Epoch 00167: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.3335 - mse: 22.3335 - val_loss: 34.1046 - val_mse: 34.1046\n",
      "Epoch 168/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.5879 - mse: 15.5879\n",
      "Epoch 00168: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3699 - mse: 21.3699 - val_loss: 29.4930 - val_mse: 29.4930\n",
      "Epoch 169/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.8105 - mse: 11.8105\n",
      "Epoch 00169: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.0812 - mse: 20.0812 - val_loss: 30.5678 - val_mse: 30.5678\n",
      "Epoch 170/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7105 - mse: 12.7105\n",
      "Epoch 00170: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.9131 - mse: 21.9131 - val_loss: 33.7334 - val_mse: 33.7334\n",
      "Epoch 171/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.4957 - mse: 11.4957\n",
      "Epoch 00171: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.8428 - mse: 22.8428 - val_loss: 29.3191 - val_mse: 29.3191\n",
      "Epoch 172/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.2110 - mse: 20.2110\n",
      "Epoch 00172: val_mse did not improve from 28.64565\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.6950 - mse: 20.6950 - val_loss: 29.0186 - val_mse: 29.0186\n",
      "Epoch 173/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.8637 - mse: 11.8637\n",
      "Epoch 00173: val_mse improved from 28.64565 to 28.47627, saving model to ./model/173-28.4763.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.8731 - mse: 20.8731 - val_loss: 28.4763 - val_mse: 28.4763\n",
      "Epoch 174/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.6338 - mse: 19.6338\n",
      "Epoch 00174: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.5979 - mse: 21.5979 - val_loss: 36.4274 - val_mse: 36.4274\n",
      "Epoch 175/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.7109 - mse: 23.7109\n",
      "Epoch 00175: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.5903 - mse: 20.5903 - val_loss: 29.6511 - val_mse: 29.6511\n",
      "Epoch 176/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.8395 - mse: 15.8395\n",
      "Epoch 00176: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.9807 - mse: 19.9807 - val_loss: 29.0581 - val_mse: 29.0581\n",
      "Epoch 177/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 29.2836 - mse: 29.2836\n",
      "Epoch 00177: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.5971 - mse: 20.5971 - val_loss: 30.3827 - val_mse: 30.3827\n",
      "Epoch 178/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7695 - mse: 12.7695\n",
      "Epoch 00178: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.5264 - mse: 21.5264 - val_loss: 31.4091 - val_mse: 31.4091\n",
      "Epoch 179/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.5264 - mse: 9.5264\n",
      "Epoch 00179: val_mse did not improve from 28.47627\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.6788 - mse: 19.6788 - val_loss: 31.9301 - val_mse: 31.9301\n",
      "Epoch 180/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.4860 - mse: 15.4860\n",
      "Epoch 00180: val_mse improved from 28.47627 to 28.13346, saving model to ./model/180-28.1335.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.8667 - mse: 19.8667 - val_loss: 28.1335 - val_mse: 28.1335\n",
      "Epoch 181/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 25.8511 - mse: 25.8511\n",
      "Epoch 00181: val_mse did not improve from 28.13346\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.5905 - mse: 20.5905 - val_loss: 29.0074 - val_mse: 29.0074\n",
      "Epoch 182/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 29.2999 - mse: 29.2999\n",
      "Epoch 00182: val_mse did not improve from 28.13346\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.8239 - mse: 20.8239 - val_loss: 32.2233 - val_mse: 32.2233\n",
      "Epoch 183/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.3919 - mse: 20.3919\n",
      "Epoch 00183: val_mse did not improve from 28.13346\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.4893 - mse: 20.4893 - val_loss: 31.2350 - val_mse: 31.2350\n",
      "Epoch 184/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.1673 - mse: 17.1673\n",
      "Epoch 00184: val_mse did not improve from 28.13346\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.9193 - mse: 21.9193 - val_loss: 37.3484 - val_mse: 37.3484\n",
      "Epoch 185/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.7506 - mse: 26.7506\n",
      "Epoch 00185: val_mse improved from 28.13346 to 27.35851, saving model to ./model/185-27.3585.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.9479 - mse: 19.9479 - val_loss: 27.3585 - val_mse: 27.3585\n",
      "Epoch 186/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.2299 - mse: 21.2299\n",
      "Epoch 00186: val_mse did not improve from 27.35851\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.7812 - mse: 18.7812 - val_loss: 29.2074 - val_mse: 29.2074\n",
      "Epoch 187/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.8975 - mse: 21.8975\n",
      "Epoch 00187: val_mse did not improve from 27.35851\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.8209 - mse: 19.8209 - val_loss: 28.9757 - val_mse: 28.9757\n",
      "Epoch 188/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.7605 - mse: 19.7605\n",
      "Epoch 00188: val_mse did not improve from 27.35851\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.3725 - mse: 18.3725 - val_loss: 29.0779 - val_mse: 29.0779\n",
      "Epoch 189/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.5310 - mse: 16.5310\n",
      "Epoch 00189: val_mse did not improve from 27.35851\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.1386 - mse: 19.1386 - val_loss: 27.6662 - val_mse: 27.6662\n",
      "Epoch 190/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.0790 - mse: 24.0790\n",
      "Epoch 00190: val_mse did not improve from 27.35851\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.4720 - mse: 19.4720 - val_loss: 31.2611 - val_mse: 31.2611\n",
      "Epoch 191/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.7498 - mse: 30.7498\n",
      "Epoch 00191: val_mse improved from 27.35851 to 26.75109, saving model to ./model/191-26.7511.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.0808 - mse: 20.0808 - val_loss: 26.7511 - val_mse: 26.7511\n",
      "Epoch 192/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 31.3279 - mse: 31.3279\n",
      "Epoch 00192: val_mse did not improve from 26.75109\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.8549 - mse: 17.8549 - val_loss: 27.6273 - val_mse: 27.6273\n",
      "Epoch 193/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.2666 - mse: 21.2666\n",
      "Epoch 00193: val_mse did not improve from 26.75109\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.3736 - mse: 19.3736 - val_loss: 29.1598 - val_mse: 29.1598\n",
      "Epoch 194/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.5141 - mse: 9.5141\n",
      "Epoch 00194: val_mse did not improve from 26.75109\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.0670 - mse: 18.0670 - val_loss: 27.3782 - val_mse: 27.3782\n",
      "Epoch 195/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 26.5447 - mse: 26.5447\n",
      "Epoch 00195: val_mse did not improve from 26.75109\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.5959 - mse: 17.5959 - val_loss: 28.7531 - val_mse: 28.7531\n",
      "Epoch 196/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.4431 - mse: 19.4431\n",
      "Epoch 00196: val_mse improved from 26.75109 to 26.65867, saving model to ./model/196-26.6587.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.9661 - mse: 18.9661 - val_loss: 26.6587 - val_mse: 26.6587\n",
      "Epoch 197/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5857 - mse: 8.5857\n",
      "Epoch 00197: val_mse did not improve from 26.65867\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3771 - mse: 21.3771 - val_loss: 34.1095 - val_mse: 34.1095\n",
      "Epoch 198/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.1607 - mse: 16.1607\n",
      "Epoch 00198: val_mse did not improve from 26.65867\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.1549 - mse: 21.1549 - val_loss: 31.9028 - val_mse: 31.9028\n",
      "Epoch 199/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 34.0495 - mse: 34.0495\n",
      "Epoch 00199: val_mse did not improve from 26.65867\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.2898 - mse: 18.2898 - val_loss: 27.1465 - val_mse: 27.1465\n",
      "Epoch 200/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.9610 - mse: 18.9610\n",
      "Epoch 00200: val_mse improved from 26.65867 to 26.60524, saving model to ./model/200-26.6052.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.8296 - mse: 19.8296 - val_loss: 26.6052 - val_mse: 26.6052\n",
      "Epoch 201/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.7528 - mse: 22.7528\n",
      "Epoch 00201: val_mse did not improve from 26.60524\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.7813 - mse: 18.7813 - val_loss: 31.0293 - val_mse: 31.0293\n",
      "Epoch 202/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.8049 - mse: 21.8049\n",
      "Epoch 00202: val_mse did not improve from 26.60524\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24.1109 - mse: 24.1109 - val_loss: 29.9170 - val_mse: 29.9170\n",
      "Epoch 203/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.1573 - mse: 23.1573\n",
      "Epoch 00203: val_mse did not improve from 26.60524\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.3779 - mse: 23.3779 - val_loss: 38.5506 - val_mse: 38.5506\n",
      "Epoch 204/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 29.3498 - mse: 29.3498\n",
      "Epoch 00204: val_mse did not improve from 26.60524\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.8995 - mse: 20.8995 - val_loss: 28.5643 - val_mse: 28.5643\n",
      "Epoch 205/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.0913 - mse: 8.0913\n",
      "Epoch 00205: val_mse improved from 26.60524 to 25.58297, saving model to ./model/205-25.5830.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.4146 - mse: 19.4146 - val_loss: 25.5830 - val_mse: 25.5830\n",
      "Epoch 206/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.1841 - mse: 33.1841\n",
      "Epoch 00206: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.1587 - mse: 19.1587 - val_loss: 29.1644 - val_mse: 29.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.6592 - mse: 15.6592\n",
      "Epoch 00207: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.6496 - mse: 18.6496 - val_loss: 26.0006 - val_mse: 26.0006\n",
      "Epoch 208/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.6294 - mse: 22.6294\n",
      "Epoch 00208: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.4307 - mse: 18.4307 - val_loss: 26.1126 - val_mse: 26.1126\n",
      "Epoch 209/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.8566 - mse: 9.8566\n",
      "Epoch 00209: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.7070 - mse: 17.7070 - val_loss: 29.0410 - val_mse: 29.0410\n",
      "Epoch 210/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.9365 - mse: 15.9365\n",
      "Epoch 00210: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5987 - mse: 16.5987 - val_loss: 26.3524 - val_mse: 26.3524\n",
      "Epoch 211/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.3585 - mse: 17.3585\n",
      "Epoch 00211: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.7667 - mse: 16.7667 - val_loss: 27.3443 - val_mse: 27.3443\n",
      "Epoch 212/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.6321 - mse: 10.6321\n",
      "Epoch 00212: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.5167 - mse: 17.5167 - val_loss: 26.1153 - val_mse: 26.1153\n",
      "Epoch 213/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 33.3503 - mse: 33.3503\n",
      "Epoch 00213: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.3720 - mse: 16.3720 - val_loss: 25.7712 - val_mse: 25.7712\n",
      "Epoch 214/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.2084 - mse: 14.2084\n",
      "Epoch 00214: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9488 - mse: 16.9488 - val_loss: 26.7789 - val_mse: 26.7789\n",
      "Epoch 215/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.0464 - mse: 24.0464\n",
      "Epoch 00215: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.1861 - mse: 17.1861 - val_loss: 30.1572 - val_mse: 30.1572\n",
      "Epoch 216/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.8894 - mse: 21.8894\n",
      "Epoch 00216: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.1280 - mse: 17.1280 - val_loss: 27.0153 - val_mse: 27.0153\n",
      "Epoch 217/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.3782 - mse: 13.3782\n",
      "Epoch 00217: val_mse did not improve from 25.58297\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9052 - mse: 16.9052 - val_loss: 26.1498 - val_mse: 26.1498\n",
      "Epoch 218/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.1402 - mse: 20.1402\n",
      "Epoch 00218: val_mse improved from 25.58297 to 25.55008, saving model to ./model/218-25.5501.hdf5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.3485 - mse: 16.3485 - val_loss: 25.5501 - val_mse: 25.5501\n",
      "Epoch 219/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.3011 - mse: 8.3011\n",
      "Epoch 00219: val_mse did not improve from 25.55008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.2110 - mse: 16.2110 - val_loss: 26.6776 - val_mse: 26.6776\n",
      "Epoch 220/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.9311 - mse: 12.9311\n",
      "Epoch 00220: val_mse did not improve from 25.55008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5908 - mse: 16.5908 - val_loss: 27.1994 - val_mse: 27.1994\n",
      "Epoch 221/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.5520 - mse: 24.5520\n",
      "Epoch 00221: val_mse improved from 25.55008 to 25.32898, saving model to ./model/221-25.3290.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.0590 - mse: 16.0590 - val_loss: 25.3290 - val_mse: 25.3290\n",
      "Epoch 222/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.2980 - mse: 16.2980\n",
      "Epoch 00222: val_mse did not improve from 25.32898\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 18.1415 - mse: 18.1415 - val_loss: 29.8962 - val_mse: 29.8962\n",
      "Epoch 223/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.4468 - mse: 19.4468\n",
      "Epoch 00223: val_mse improved from 25.32898 to 25.13272, saving model to ./model/223-25.1327.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.1171 - mse: 17.1171 - val_loss: 25.1327 - val_mse: 25.1327\n",
      "Epoch 224/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4880 - mse: 8.4880\n",
      "Epoch 00224: val_mse did not improve from 25.13272\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5406 - mse: 16.5406 - val_loss: 25.8246 - val_mse: 25.8246\n",
      "Epoch 225/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.5858 - mse: 14.5858\n",
      "Epoch 00225: val_mse did not improve from 25.13272\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.6768 - mse: 15.6768 - val_loss: 25.8299 - val_mse: 25.8299\n",
      "Epoch 226/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.2560 - mse: 10.2560\n",
      "Epoch 00226: val_mse did not improve from 25.13272\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.1262 - mse: 16.1262 - val_loss: 25.4199 - val_mse: 25.4199\n",
      "Epoch 227/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.8546 - mse: 15.8546\n",
      "Epoch 00227: val_mse improved from 25.13272 to 25.04663, saving model to ./model/227-25.0466.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.5758 - mse: 16.5758 - val_loss: 25.0466 - val_mse: 25.0466\n",
      "Epoch 228/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.5680 - mse: 17.5680\n",
      "Epoch 00228: val_mse did not improve from 25.04663\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.6427 - mse: 16.6427 - val_loss: 29.2825 - val_mse: 29.2825\n",
      "Epoch 229/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.2234 - mse: 21.2234\n",
      "Epoch 00229: val_mse did not improve from 25.04663\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.1746 - mse: 16.1746 - val_loss: 27.7899 - val_mse: 27.7899\n",
      "Epoch 230/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.5704 - mse: 22.5704\n",
      "Epoch 00230: val_mse did not improve from 25.04663\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.4371 - mse: 16.4371 - val_loss: 25.8845 - val_mse: 25.8845\n",
      "Epoch 231/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.4214 - mse: 15.4214\n",
      "Epoch 00231: val_mse did not improve from 25.04663\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9300 - mse: 16.9300 - val_loss: 25.5353 - val_mse: 25.5353\n",
      "Epoch 232/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.3491 - mse: 20.3491\n",
      "Epoch 00232: val_mse improved from 25.04663 to 24.60633, saving model to ./model/232-24.6063.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.6013 - mse: 15.6013 - val_loss: 24.6063 - val_mse: 24.6063\n",
      "Epoch 233/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.4571 - mse: 10.4571\n",
      "Epoch 00233: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.2181 - mse: 16.2181 - val_loss: 25.6099 - val_mse: 25.6099\n",
      "Epoch 234/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7004 - mse: 6.7004\n",
      "Epoch 00234: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.6530 - mse: 17.6530 - val_loss: 26.3393 - val_mse: 26.3393\n",
      "Epoch 235/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.7437 - mse: 11.7437\n",
      "Epoch 00235: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.4515 - mse: 18.4515 - val_loss: 27.1797 - val_mse: 27.1797\n",
      "Epoch 236/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.5270 - mse: 16.5270\n",
      "Epoch 00236: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.4290 - mse: 17.4290 - val_loss: 28.3828 - val_mse: 28.3828\n",
      "Epoch 237/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2743 - mse: 13.2743\n",
      "Epoch 00237: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.1328 - mse: 18.1328 - val_loss: 32.2407 - val_mse: 32.2407\n",
      "Epoch 238/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.1348 - mse: 19.1348\n",
      "Epoch 00238: val_mse did not improve from 24.60633\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.5497 - mse: 18.5497 - val_loss: 36.5953 - val_mse: 36.5953\n",
      "Epoch 239/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 34.3230 - mse: 34.3230\n",
      "Epoch 00239: val_mse improved from 24.60633 to 24.47086, saving model to ./model/239-24.4709.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.0501 - mse: 20.0501 - val_loss: 24.4709 - val_mse: 24.4709\n",
      "Epoch 240/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.7622 - mse: 9.7622\n",
      "Epoch 00240: val_mse did not improve from 24.47086\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.7001 - mse: 17.7001 - val_loss: 26.4288 - val_mse: 26.4288\n",
      "Epoch 241/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.4348 - mse: 12.4348\n",
      "Epoch 00241: val_mse did not improve from 24.47086\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 15.7575 - mse: 15.7575 - val_loss: 28.3610 - val_mse: 28.3610\n",
      "Epoch 242/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.5442 - mse: 23.5442\n",
      "Epoch 00242: val_mse did not improve from 24.47086\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.8062 - mse: 15.8062 - val_loss: 25.6927 - val_mse: 25.6927\n",
      "Epoch 243/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.3415 - mse: 14.3415\n",
      "Epoch 00243: val_mse improved from 24.47086 to 24.28930, saving model to ./model/243-24.2893.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.8055 - mse: 15.8055 - val_loss: 24.2893 - val_mse: 24.2893\n",
      "Epoch 244/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.7842 - mse: 23.7842\n",
      "Epoch 00244: val_mse did not improve from 24.28930\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.3151 - mse: 15.3151 - val_loss: 25.7042 - val_mse: 25.7042\n",
      "Epoch 245/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.8716 - mse: 14.8716\n",
      "Epoch 00245: val_mse did not improve from 24.28930\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.0331 - mse: 15.0331 - val_loss: 25.9532 - val_mse: 25.9532\n",
      "Epoch 246/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.3934 - mse: 8.3934\n",
      "Epoch 00246: val_mse did not improve from 24.28930\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.2547 - mse: 15.2547 - val_loss: 29.7317 - val_mse: 29.7317\n",
      "Epoch 247/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.6510 - mse: 12.6510\n",
      "Epoch 00247: val_mse did not improve from 24.28930\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.5579 - mse: 15.5579 - val_loss: 24.8122 - val_mse: 24.8122\n",
      "Epoch 248/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.3319 - mse: 16.3319\n",
      "Epoch 00248: val_mse improved from 24.28930 to 23.57024, saving model to ./model/248-23.5702.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.4796 - mse: 15.4796 - val_loss: 23.5702 - val_mse: 23.5702\n",
      "Epoch 249/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.7659 - mse: 10.7659\n",
      "Epoch 00249: val_mse did not improve from 23.57024\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.9961 - mse: 14.9961 - val_loss: 24.4393 - val_mse: 24.4393\n",
      "Epoch 250/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.8272 - mse: 12.8272\n",
      "Epoch 00250: val_mse did not improve from 23.57024\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.3104 - mse: 15.3104 - val_loss: 25.7974 - val_mse: 25.7974\n",
      "Epoch 251/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.7106 - mse: 15.7106\n",
      "Epoch 00251: val_mse did not improve from 23.57024\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.4657 - mse: 14.4657 - val_loss: 23.7881 - val_mse: 23.7881\n",
      "Epoch 252/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.0651 - mse: 13.0651\n",
      "Epoch 00252: val_mse did not improve from 23.57024\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.7036 - mse: 15.7036 - val_loss: 23.6437 - val_mse: 23.6437\n",
      "Epoch 253/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.2986 - mse: 15.2986\n",
      "Epoch 00253: val_mse did not improve from 23.57024\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.5833 - mse: 15.5833 - val_loss: 27.8473 - val_mse: 27.8473\n",
      "Epoch 254/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1440 - mse: 11.1440\n",
      "Epoch 00254: val_mse improved from 23.57024 to 23.16840, saving model to ./model/254-23.1684.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.9798 - mse: 14.9798 - val_loss: 23.1684 - val_mse: 23.1684\n",
      "Epoch 255/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5030 - mse: 12.5030\n",
      "Epoch 00255: val_mse did not improve from 23.16840\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.6138 - mse: 15.6138 - val_loss: 30.1384 - val_mse: 30.1384\n",
      "Epoch 256/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7565 - mse: 7.7565\n",
      "Epoch 00256: val_mse improved from 23.16840 to 22.85342, saving model to ./model/256-22.8534.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.8474 - mse: 19.8474 - val_loss: 22.8534 - val_mse: 22.8534\n",
      "Epoch 257/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.3065 - mse: 22.3065\n",
      "Epoch 00257: val_mse improved from 22.85342 to 22.65008, saving model to ./model/257-22.6501.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.4378 - mse: 17.4378 - val_loss: 22.6501 - val_mse: 22.6501\n",
      "Epoch 258/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.3621 - mse: 19.3621\n",
      "Epoch 00258: val_mse did not improve from 22.65008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.1288 - mse: 14.1288 - val_loss: 24.4897 - val_mse: 24.4897\n",
      "Epoch 259/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.0123 - mse: 19.0123\n",
      "Epoch 00259: val_mse did not improve from 22.65008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.9039 - mse: 13.9039 - val_loss: 24.1181 - val_mse: 24.1181\n",
      "Epoch 260/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.1146 - mse: 7.1146\n",
      "Epoch 00260: val_mse did not improve from 22.65008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6440 - mse: 13.6440 - val_loss: 23.6032 - val_mse: 23.6032\n",
      "Epoch 261/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.8395 - mse: 14.8395\n",
      "Epoch 00261: val_mse did not improve from 22.65008\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2602 - mse: 13.2602 - val_loss: 24.3397 - val_mse: 24.3397\n",
      "Epoch 262/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.3188 - mse: 14.3188\n",
      "Epoch 00262: val_mse improved from 22.65008 to 22.23517, saving model to ./model/262-22.2352.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.2432 - mse: 15.2432 - val_loss: 22.2352 - val_mse: 22.2352\n",
      "Epoch 263/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7409 - mse: 12.7409\n",
      "Epoch 00263: val_mse did not improve from 22.23517\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.4149 - mse: 14.4149 - val_loss: 33.5102 - val_mse: 33.5102\n",
      "Epoch 264/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.3579 - mse: 15.3579\n",
      "Epoch 00264: val_mse did not improve from 22.23517\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.7740 - mse: 14.7740 - val_loss: 23.3525 - val_mse: 23.3525\n",
      "Epoch 265/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.9036 - mse: 12.9036\n",
      "Epoch 00265: val_mse did not improve from 22.23517\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.6630 - mse: 15.6630 - val_loss: 23.3003 - val_mse: 23.3003\n",
      "Epoch 266/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.4076 - mse: 10.4076\n",
      "Epoch 00266: val_mse improved from 22.23517 to 22.12881, saving model to ./model/266-22.1288.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.3674 - mse: 15.3674 - val_loss: 22.1288 - val_mse: 22.1288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.8471 - mse: 12.8471\n",
      "Epoch 00267: val_mse did not improve from 22.12881\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6561 - mse: 13.6561 - val_loss: 25.5360 - val_mse: 25.5360\n",
      "Epoch 268/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.6520 - mse: 16.6520\n",
      "Epoch 00268: val_mse improved from 22.12881 to 21.86845, saving model to ./model/268-21.8684.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.8548 - mse: 13.8548 - val_loss: 21.8684 - val_mse: 21.8684\n",
      "Epoch 269/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7389 - mse: 12.7389\n",
      "Epoch 00269: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6386 - mse: 13.6386 - val_loss: 23.1611 - val_mse: 23.1611\n",
      "Epoch 270/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.3257 - mse: 10.3257\n",
      "Epoch 00270: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.3173 - mse: 13.3173 - val_loss: 25.1120 - val_mse: 25.1120\n",
      "Epoch 271/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.8834 - mse: 13.8834\n",
      "Epoch 00271: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2596 - mse: 13.2596 - val_loss: 22.6840 - val_mse: 22.6840\n",
      "Epoch 272/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.2198 - mse: 9.2198\n",
      "Epoch 00272: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.9760 - mse: 12.9760 - val_loss: 24.1402 - val_mse: 24.1402\n",
      "Epoch 273/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.7762 - mse: 10.7762\n",
      "Epoch 00273: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.8480 - mse: 13.8480 - val_loss: 26.2027 - val_mse: 26.2027\n",
      "Epoch 274/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.9913 - mse: 16.9913\n",
      "Epoch 00274: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.9536 - mse: 14.9536 - val_loss: 23.2191 - val_mse: 23.2191\n",
      "Epoch 275/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2739 - mse: 13.2739\n",
      "Epoch 00275: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.7069 - mse: 12.7069 - val_loss: 22.2383 - val_mse: 22.2383\n",
      "Epoch 276/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1035 - mse: 11.1035\n",
      "Epoch 00276: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.0608 - mse: 13.0608 - val_loss: 22.3527 - val_mse: 22.3527\n",
      "Epoch 277/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.4219 - mse: 20.4219\n",
      "Epoch 00277: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.5638 - mse: 13.5638 - val_loss: 23.6881 - val_mse: 23.6881\n",
      "Epoch 278/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8071 - mse: 8.8071\n",
      "Epoch 00278: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2326 - mse: 13.2326 - val_loss: 23.1583 - val_mse: 23.1583\n",
      "Epoch 279/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.6982 - mse: 20.6982\n",
      "Epoch 00279: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.7909 - mse: 13.7909 - val_loss: 22.7437 - val_mse: 22.7437\n",
      "Epoch 280/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2116 - mse: 11.2116\n",
      "Epoch 00280: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.4880 - mse: 15.4880 - val_loss: 27.8219 - val_mse: 27.8219\n",
      "Epoch 281/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.6194 - mse: 11.6194\n",
      "Epoch 00281: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.8399 - mse: 17.8399 - val_loss: 24.8602 - val_mse: 24.8602\n",
      "Epoch 282/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.8624 - mse: 9.8624\n",
      "Epoch 00282: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.0999 - mse: 15.0999 - val_loss: 24.6701 - val_mse: 24.6701\n",
      "Epoch 283/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.0296 - mse: 17.0296\n",
      "Epoch 00283: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2894 - mse: 13.2894 - val_loss: 28.7758 - val_mse: 28.7758\n",
      "Epoch 284/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.0365 - mse: 10.0365\n",
      "Epoch 00284: val_mse did not improve from 21.86845\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.3676 - mse: 14.3676 - val_loss: 25.3738 - val_mse: 25.3738\n",
      "Epoch 285/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.1276 - mse: 19.1276\n",
      "Epoch 00285: val_mse improved from 21.86845 to 21.59068, saving model to ./model/285-21.5907.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.9215 - mse: 13.9215 - val_loss: 21.5907 - val_mse: 21.5907\n",
      "Epoch 286/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.4911 - mse: 15.4911\n",
      "Epoch 00286: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.4061 - mse: 12.4061 - val_loss: 21.6077 - val_mse: 21.6077\n",
      "Epoch 287/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.9651 - mse: 11.9651\n",
      "Epoch 00287: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6481 - mse: 13.6481 - val_loss: 27.8036 - val_mse: 27.8036\n",
      "Epoch 288/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.6744 - mse: 20.6744\n",
      "Epoch 00288: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.8364 - mse: 17.8364 - val_loss: 26.7866 - val_mse: 26.7866\n",
      "Epoch 289/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.0264 - mse: 19.0264\n",
      "Epoch 00289: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.3728 - mse: 20.3728 - val_loss: 22.7301 - val_mse: 22.7301\n",
      "Epoch 290/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.5917 - mse: 16.5917\n",
      "Epoch 00290: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.3173 - mse: 15.3173 - val_loss: 23.4347 - val_mse: 23.4347\n",
      "Epoch 291/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.2677 - mse: 15.2677\n",
      "Epoch 00291: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.9049 - mse: 14.9049 - val_loss: 32.7586 - val_mse: 32.7586\n",
      "Epoch 292/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.4830 - mse: 17.4830\n",
      "Epoch 00292: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.6132 - mse: 18.6132 - val_loss: 23.8078 - val_mse: 23.8078\n",
      "Epoch 293/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.5965 - mse: 13.5965\n",
      "Epoch 00293: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.3872 - mse: 13.3872 - val_loss: 24.2376 - val_mse: 24.2376\n",
      "Epoch 294/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2431 - mse: 11.2431\n",
      "Epoch 00294: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.2338 - mse: 14.2338 - val_loss: 21.9666 - val_mse: 21.9666\n",
      "Epoch 295/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.7636 - mse: 9.7636\n",
      "Epoch 00295: val_mse did not improve from 21.59068\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.6788 - mse: 12.6788 - val_loss: 23.7823 - val_mse: 23.7823\n",
      "Epoch 296/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.1625 - mse: 12.1625\n",
      "Epoch 00296: val_mse improved from 21.59068 to 20.86837, saving model to ./model/296-20.8684.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.8116 - mse: 12.8116 - val_loss: 20.8684 - val_mse: 20.8684\n",
      "Epoch 297/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.4325 - mse: 6.4325\n",
      "Epoch 00297: val_mse did not improve from 20.86837\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.6769 - mse: 12.6769 - val_loss: 22.7867 - val_mse: 22.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.1297 - mse: 21.1297\n",
      "Epoch 00298: val_mse did not improve from 20.86837\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.5482 - mse: 14.5482 - val_loss: 23.9459 - val_mse: 23.9459\n",
      "Epoch 299/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.3339 - mse: 20.3339\n",
      "Epoch 00299: val_mse did not improve from 20.86837\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.0467 - mse: 15.0467 - val_loss: 26.0590 - val_mse: 26.0590\n",
      "Epoch 300/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.0560 - mse: 10.0560\n",
      "Epoch 00300: val_mse did not improve from 20.86837\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.9984 - mse: 12.9984 - val_loss: 21.8475 - val_mse: 21.8475\n",
      "Epoch 301/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.8048 - mse: 15.8048\n",
      "Epoch 00301: val_mse did not improve from 20.86837\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8336 - mse: 12.8336 - val_loss: 21.8127 - val_mse: 21.8127\n",
      "Epoch 302/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.9442 - mse: 3.9442\n",
      "Epoch 00302: val_mse improved from 20.86837 to 20.61823, saving model to ./model/302-20.6182.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.5993 - mse: 12.5993 - val_loss: 20.6182 - val_mse: 20.6182\n",
      "Epoch 303/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.9989 - mse: 10.9989\n",
      "Epoch 00303: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8585 - mse: 12.8585 - val_loss: 23.7558 - val_mse: 23.7558\n",
      "Epoch 304/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.0921 - mse: 15.0921\n",
      "Epoch 00304: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6820 - mse: 13.6820 - val_loss: 22.9198 - val_mse: 22.9198\n",
      "Epoch 305/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8884 - mse: 10.8884\n",
      "Epoch 00305: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.9063 - mse: 13.9063 - val_loss: 23.3619 - val_mse: 23.3619\n",
      "Epoch 306/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.4151 - mse: 12.4151\n",
      "Epoch 00306: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.6909 - mse: 12.6909 - val_loss: 28.6210 - val_mse: 28.6210\n",
      "Epoch 307/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.1598 - mse: 17.1598\n",
      "Epoch 00307: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6638 - mse: 13.6638 - val_loss: 20.6288 - val_mse: 20.6288\n",
      "Epoch 308/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24.0022 - mse: 24.0022\n",
      "Epoch 00308: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6320 - mse: 13.6320 - val_loss: 22.0196 - val_mse: 22.0196\n",
      "Epoch 309/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.9713 - mse: 10.9713\n",
      "Epoch 00309: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.0376 - mse: 12.0376 - val_loss: 21.7182 - val_mse: 21.7182\n",
      "Epoch 310/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.8820 - mse: 11.8820\n",
      "Epoch 00310: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.3189 - mse: 13.3189 - val_loss: 22.8227 - val_mse: 22.8227\n",
      "Epoch 311/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6727 - mse: 6.6727\n",
      "Epoch 00311: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6672 - mse: 13.6672 - val_loss: 21.6902 - val_mse: 21.6902\n",
      "Epoch 312/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.8781 - mse: 9.8781\n",
      "Epoch 00312: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6384 - mse: 13.6384 - val_loss: 21.0759 - val_mse: 21.0759\n",
      "Epoch 313/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.9073 - mse: 6.9073\n",
      "Epoch 00313: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.5365 - mse: 12.5365 - val_loss: 21.9045 - val_mse: 21.9045\n",
      "Epoch 314/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.6381 - mse: 9.6381\n",
      "Epoch 00314: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3294 - mse: 12.3294 - val_loss: 26.2977 - val_mse: 26.2977\n",
      "Epoch 315/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.1133 - mse: 17.1133\n",
      "Epoch 00315: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.1751 - mse: 17.1751 - val_loss: 24.2617 - val_mse: 24.2617\n",
      "Epoch 316/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.9192 - mse: 12.9192\n",
      "Epoch 00316: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.3229 - mse: 17.3229 - val_loss: 30.8362 - val_mse: 30.8362\n",
      "Epoch 317/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.6730 - mse: 23.6730\n",
      "Epoch 00317: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.1614 - mse: 18.1614 - val_loss: 29.1826 - val_mse: 29.1826\n",
      "Epoch 318/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.1439 - mse: 13.1439\n",
      "Epoch 00318: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.0922 - mse: 19.0922 - val_loss: 21.7255 - val_mse: 21.7255\n",
      "Epoch 319/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2043 - mse: 11.2043\n",
      "Epoch 00319: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.1392 - mse: 15.1392 - val_loss: 22.8700 - val_mse: 22.8700\n",
      "Epoch 320/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.1926 - mse: 15.1926\n",
      "Epoch 00320: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.4837 - mse: 12.4837 - val_loss: 23.5976 - val_mse: 23.5976\n",
      "Epoch 321/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7896 - mse: 7.7896\n",
      "Epoch 00321: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.7233 - mse: 13.7233 - val_loss: 23.7695 - val_mse: 23.7695\n",
      "Epoch 322/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.1946 - mse: 10.1946\n",
      "Epoch 00322: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2914 - mse: 13.2914 - val_loss: 24.3549 - val_mse: 24.3549\n",
      "Epoch 323/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1505 - mse: 11.1505\n",
      "Epoch 00323: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.4646 - mse: 12.4646 - val_loss: 21.9657 - val_mse: 21.9657\n",
      "Epoch 324/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.7214 - mse: 14.7214\n",
      "Epoch 00324: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.8997 - mse: 11.8997 - val_loss: 21.1641 - val_mse: 21.1641\n",
      "Epoch 325/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.0364 - mse: 4.0364\n",
      "Epoch 00325: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.2507 - mse: 12.2507 - val_loss: 22.4184 - val_mse: 22.4184\n",
      "Epoch 326/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.9845 - mse: 6.9845\n",
      "Epoch 00326: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.4119 - mse: 11.4119 - val_loss: 30.6109 - val_mse: 30.6109\n",
      "Epoch 327/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 30.4522 - mse: 30.4522\n",
      "Epoch 00327: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.6855 - mse: 14.6855 - val_loss: 23.2985 - val_mse: 23.2985\n",
      "Epoch 328/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.9575 - mse: 13.9575\n",
      "Epoch 00328: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.2166 - mse: 12.2166 - val_loss: 21.6174 - val_mse: 21.6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.0994 - mse: 11.0994\n",
      "Epoch 00329: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.7649 - mse: 11.7649 - val_loss: 20.9573 - val_mse: 20.9573\n",
      "Epoch 330/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.1188 - mse: 14.1188\n",
      "Epoch 00330: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1439 - mse: 12.1439 - val_loss: 20.9948 - val_mse: 20.9948\n",
      "Epoch 331/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.4311 - mse: 11.4311\n",
      "Epoch 00331: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.7919 - mse: 11.7919 - val_loss: 21.6509 - val_mse: 21.6509\n",
      "Epoch 332/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.4087 - mse: 9.4087\n",
      "Epoch 00332: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.4881 - mse: 11.4881 - val_loss: 24.0609 - val_mse: 24.0609\n",
      "Epoch 333/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.5876 - mse: 16.5876\n",
      "Epoch 00333: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3853 - mse: 12.3853 - val_loss: 24.7126 - val_mse: 24.7126\n",
      "Epoch 334/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.3887 - mse: 5.3887\n",
      "Epoch 00334: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3366 - mse: 12.3366 - val_loss: 21.7942 - val_mse: 21.7942\n",
      "Epoch 335/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4720 - mse: 7.4720\n",
      "Epoch 00335: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.4315 - mse: 11.4315 - val_loss: 21.1874 - val_mse: 21.1874\n",
      "Epoch 336/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.7034 - mse: 16.7034\n",
      "Epoch 00336: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.7437 - mse: 11.7437 - val_loss: 21.1781 - val_mse: 21.1781\n",
      "Epoch 337/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0227 - mse: 7.0227\n",
      "Epoch 00337: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2515 - mse: 13.2515 - val_loss: 23.4164 - val_mse: 23.4164\n",
      "Epoch 338/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.5527 - mse: 11.5527\n",
      "Epoch 00338: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.8979 - mse: 13.8979 - val_loss: 30.2694 - val_mse: 30.2694\n",
      "Epoch 339/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.8482 - mse: 17.8482\n",
      "Epoch 00339: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.4047 - mse: 14.4047 - val_loss: 22.4889 - val_mse: 22.4889\n",
      "Epoch 340/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.3296 - mse: 4.3296\n",
      "Epoch 00340: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.0857 - mse: 12.0857 - val_loss: 21.8843 - val_mse: 21.8843\n",
      "Epoch 341/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.9768 - mse: 10.9768\n",
      "Epoch 00341: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1124 - mse: 12.1124 - val_loss: 21.5370 - val_mse: 21.5370\n",
      "Epoch 342/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.6370 - mse: 14.6370\n",
      "Epoch 00342: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.2604 - mse: 12.2604 - val_loss: 21.3136 - val_mse: 21.3136\n",
      "Epoch 343/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1390 - mse: 6.1390\n",
      "Epoch 00343: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3749 - mse: 12.3749 - val_loss: 22.4406 - val_mse: 22.4406\n",
      "Epoch 344/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7822 - mse: 6.7822\n",
      "Epoch 00344: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.7109 - mse: 11.7109 - val_loss: 22.5995 - val_mse: 22.5995\n",
      "Epoch 345/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.6303 - mse: 7.6303\n",
      "Epoch 00345: val_mse did not improve from 20.61823\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.2046 - mse: 12.2046 - val_loss: 22.8258 - val_mse: 22.8258\n",
      "Epoch 346/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7279 - mse: 7.7279\n",
      "Epoch 00346: val_mse improved from 20.61823 to 20.10545, saving model to ./model/346-20.1054.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.1676 - mse: 12.1676 - val_loss: 20.1054 - val_mse: 20.1054\n",
      "Epoch 347/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.9610 - mse: 3.9610\n",
      "Epoch 00347: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 11.3060 - mse: 11.3060 - val_loss: 20.9959 - val_mse: 20.9959\n",
      "Epoch 348/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.1103 - mse: 8.1103\n",
      "Epoch 00348: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8242 - mse: 12.8242 - val_loss: 23.9210 - val_mse: 23.9210\n",
      "Epoch 349/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.6480 - mse: 15.6480\n",
      "Epoch 00349: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0627 - mse: 11.0627 - val_loss: 21.4768 - val_mse: 21.4768\n",
      "Epoch 350/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.7976 - mse: 16.7976\n",
      "Epoch 00350: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2509 - mse: 11.2509 - val_loss: 21.5167 - val_mse: 21.5167\n",
      "Epoch 351/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.8594 - mse: 9.8594\n",
      "Epoch 00351: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3920 - mse: 11.3920 - val_loss: 20.8686 - val_mse: 20.8686\n",
      "Epoch 352/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5108 - mse: 12.5108\n",
      "Epoch 00352: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3903 - mse: 11.3903 - val_loss: 21.7450 - val_mse: 21.7450\n",
      "Epoch 353/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7023 - mse: 8.7023\n",
      "Epoch 00353: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.1956 - mse: 11.1956 - val_loss: 20.7335 - val_mse: 20.7335\n",
      "Epoch 354/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.3484 - mse: 11.3484\n",
      "Epoch 00354: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3630 - mse: 12.3630 - val_loss: 23.2476 - val_mse: 23.2476\n",
      "Epoch 355/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2532 - mse: 13.2532\n",
      "Epoch 00355: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.5996 - mse: 13.5996 - val_loss: 39.0778 - val_mse: 39.0778\n",
      "Epoch 356/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.3665 - mse: 18.3665\n",
      "Epoch 00356: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.1567 - mse: 22.1567 - val_loss: 23.0084 - val_mse: 23.0084\n",
      "Epoch 357/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.9737 - mse: 14.9737\n",
      "Epoch 00357: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.8729 - mse: 13.8729 - val_loss: 22.4703 - val_mse: 22.4703\n",
      "Epoch 358/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7913 - mse: 12.7913\n",
      "Epoch 00358: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2094 - mse: 11.2094 - val_loss: 22.1738 - val_mse: 22.1738\n",
      "Epoch 359/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.5340 - mse: 9.5340\n",
      "Epoch 00359: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2360 - mse: 11.2360 - val_loss: 20.9662 - val_mse: 20.9662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.7232 - mse: 13.7232\n",
      "Epoch 00360: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.9265 - mse: 11.9265 - val_loss: 21.0446 - val_mse: 21.0446\n",
      "Epoch 361/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.1224 - mse: 21.1224\n",
      "Epoch 00361: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2436 - mse: 13.2436 - val_loss: 21.9736 - val_mse: 21.9736\n",
      "Epoch 362/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2940 - mse: 11.2940\n",
      "Epoch 00362: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.6341 - mse: 12.6341 - val_loss: 23.0777 - val_mse: 23.0777\n",
      "Epoch 363/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8369 - mse: 10.8369\n",
      "Epoch 00363: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.5513 - mse: 11.5513 - val_loss: 21.7671 - val_mse: 21.7671\n",
      "Epoch 364/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.8746 - mse: 12.8746\n",
      "Epoch 00364: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.5184 - mse: 12.5184 - val_loss: 25.1766 - val_mse: 25.1766\n",
      "Epoch 365/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0569 - mse: 7.0569\n",
      "Epoch 00365: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.1608 - mse: 11.1608 - val_loss: 21.1549 - val_mse: 21.1549\n",
      "Epoch 366/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.8445 - mse: 13.8445\n",
      "Epoch 00366: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.5634 - mse: 12.5634 - val_loss: 23.0620 - val_mse: 23.0620\n",
      "Epoch 367/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 22.0788 - mse: 22.0788\n",
      "Epoch 00367: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3610 - mse: 12.3610 - val_loss: 20.5737 - val_mse: 20.5737\n",
      "Epoch 368/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.7128 - mse: 10.7128\n",
      "Epoch 00368: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1589 - mse: 12.1589 - val_loss: 20.8920 - val_mse: 20.8920\n",
      "Epoch 369/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.3870 - mse: 5.3870\n",
      "Epoch 00369: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.6137 - mse: 14.6137 - val_loss: 21.2396 - val_mse: 21.2396\n",
      "Epoch 370/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7676 - mse: 7.7676\n",
      "Epoch 00370: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.0919 - mse: 12.0919 - val_loss: 33.0094 - val_mse: 33.0094\n",
      "Epoch 371/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.9155 - mse: 17.9155\n",
      "Epoch 00371: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 15.0773 - mse: 15.0773 - val_loss: 22.8978 - val_mse: 22.8978\n",
      "Epoch 372/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5519 - mse: 8.5519\n",
      "Epoch 00372: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.8801 - mse: 14.8801 - val_loss: 21.3483 - val_mse: 21.3483\n",
      "Epoch 373/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.0273 - mse: 14.0273\n",
      "Epoch 00373: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.1465 - mse: 13.1465 - val_loss: 22.9407 - val_mse: 22.9407\n",
      "Epoch 374/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2895 - mse: 8.2895\n",
      "Epoch 00374: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2641 - mse: 11.2641 - val_loss: 20.5992 - val_mse: 20.5992\n",
      "Epoch 375/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.6517 - mse: 9.6517\n",
      "Epoch 00375: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4703 - mse: 10.4703 - val_loss: 21.1293 - val_mse: 21.1293\n",
      "Epoch 376/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.0941 - mse: 14.0941\n",
      "Epoch 00376: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.0900 - mse: 13.0900 - val_loss: 21.4178 - val_mse: 21.4178\n",
      "Epoch 377/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.0220 - mse: 12.0220\n",
      "Epoch 00377: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.1330 - mse: 11.1330 - val_loss: 21.2738 - val_mse: 21.2738\n",
      "Epoch 378/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.0385 - mse: 10.0385\n",
      "Epoch 00378: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2636 - mse: 13.2636 - val_loss: 22.7669 - val_mse: 22.7669\n",
      "Epoch 379/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.0844 - mse: 15.0844\n",
      "Epoch 00379: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.9919 - mse: 11.9919 - val_loss: 20.8653 - val_mse: 20.8653\n",
      "Epoch 380/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1465 - mse: 11.1465\n",
      "Epoch 00380: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5083 - mse: 10.5083 - val_loss: 26.1077 - val_mse: 26.1077\n",
      "Epoch 381/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.7620 - mse: 9.7620\n",
      "Epoch 00381: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.5622 - mse: 11.5622 - val_loss: 20.7806 - val_mse: 20.7806\n",
      "Epoch 382/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.6264 - mse: 7.6264\n",
      "Epoch 00382: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5859 - mse: 10.5859 - val_loss: 21.9249 - val_mse: 21.9249\n",
      "Epoch 383/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5130 - mse: 8.5130\n",
      "Epoch 00383: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2410 - mse: 11.2410 - val_loss: 20.6259 - val_mse: 20.6259\n",
      "Epoch 384/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.4956 - mse: 5.4956\n",
      "Epoch 00384: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3672 - mse: 11.3672 - val_loss: 21.2632 - val_mse: 21.2632\n",
      "Epoch 385/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.0215 - mse: 9.0215\n",
      "Epoch 00385: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0310 - mse: 11.0310 - val_loss: 20.3073 - val_mse: 20.3073\n",
      "Epoch 386/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.8455 - mse: 5.8455\n",
      "Epoch 00386: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.6273 - mse: 10.6273 - val_loss: 20.5598 - val_mse: 20.5598\n",
      "Epoch 387/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.3686 - mse: 5.3686\n",
      "Epoch 00387: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5057 - mse: 10.5057 - val_loss: 23.0882 - val_mse: 23.0882\n",
      "Epoch 388/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.0766 - mse: 15.0766\n",
      "Epoch 00388: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5909 - mse: 10.5909 - val_loss: 21.3499 - val_mse: 21.3499\n",
      "Epoch 389/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.1215 - mse: 13.1215\n",
      "Epoch 00389: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.7035 - mse: 10.7035 - val_loss: 21.4207 - val_mse: 21.4207\n",
      "Epoch 390/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 18.8041 - mse: 18.8041\n",
      "Epoch 00390: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.6824 - mse: 13.6824 - val_loss: 29.0533 - val_mse: 29.0533\n",
      "Epoch 391/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 12.2722 - mse: 12.2722\n",
      "Epoch 00391: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5028 - mse: 16.5028 - val_loss: 21.8929 - val_mse: 21.8929\n",
      "Epoch 392/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5270 - mse: 12.5270\n",
      "Epoch 00392: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2012 - mse: 11.2012 - val_loss: 21.0759 - val_mse: 21.0759\n",
      "Epoch 393/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.8928 - mse: 7.8928\n",
      "Epoch 00393: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.8062 - mse: 10.8062 - val_loss: 21.7724 - val_mse: 21.7724\n",
      "Epoch 394/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5505 - mse: 8.5505\n",
      "Epoch 00394: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.5954 - mse: 11.5954 - val_loss: 20.4887 - val_mse: 20.4887\n",
      "Epoch 395/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.3084 - mse: 6.3084\n",
      "Epoch 00395: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.9801 - mse: 11.9801 - val_loss: 21.2885 - val_mse: 21.2885\n",
      "Epoch 396/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6488 - mse: 8.6488\n",
      "Epoch 00396: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1929 - mse: 10.1929 - val_loss: 21.2638 - val_mse: 21.2638\n",
      "Epoch 397/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.5670 - mse: 11.5670\n",
      "Epoch 00397: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5879 - mse: 10.5879 - val_loss: 22.2428 - val_mse: 22.2428\n",
      "Epoch 398/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.9710 - mse: 13.9710\n",
      "Epoch 00398: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3446 - mse: 11.3446 - val_loss: 20.9438 - val_mse: 20.9438\n",
      "Epoch 399/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.5018 - mse: 14.5018\n",
      "Epoch 00399: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.3181 - mse: 10.3181 - val_loss: 20.6376 - val_mse: 20.6376\n",
      "Epoch 400/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.4217 - mse: 9.4217\n",
      "Epoch 00400: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.3241 - mse: 10.3241 - val_loss: 21.2287 - val_mse: 21.2287\n",
      "Epoch 401/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.9270 - mse: 19.9270\n",
      "Epoch 00401: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1143 - mse: 12.1143 - val_loss: 21.1689 - val_mse: 21.1689\n",
      "Epoch 402/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.1591 - mse: 7.1591\n",
      "Epoch 00402: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.9788 - mse: 10.9788 - val_loss: 20.5098 - val_mse: 20.5098\n",
      "Epoch 403/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.2676 - mse: 3.2676\n",
      "Epoch 00403: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.0883 - mse: 10.0883 - val_loss: 20.6077 - val_mse: 20.6077\n",
      "Epoch 404/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.6718 - mse: 14.6718\n",
      "Epoch 00404: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7861 - mse: 9.7861 - val_loss: 20.7089 - val_mse: 20.7089\n",
      "Epoch 405/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.6371 - mse: 11.6371\n",
      "Epoch 00405: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.6575 - mse: 10.6575 - val_loss: 20.2225 - val_mse: 20.2225\n",
      "Epoch 406/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.1790 - mse: 4.1790\n",
      "Epoch 00406: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5932 - mse: 10.5932 - val_loss: 21.4921 - val_mse: 21.4921\n",
      "Epoch 407/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0490 - mse: 6.0490\n",
      "Epoch 00407: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.0554 - mse: 10.0554 - val_loss: 23.0994 - val_mse: 23.0994\n",
      "Epoch 408/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.3100 - mse: 7.3100\n",
      "Epoch 00408: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.5446 - mse: 11.5446 - val_loss: 20.2900 - val_mse: 20.2900\n",
      "Epoch 409/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5298 - mse: 5.5298\n",
      "Epoch 00409: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.3671 - mse: 14.3671 - val_loss: 20.5522 - val_mse: 20.5522\n",
      "Epoch 410/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.6209 - mse: 7.6209\n",
      "Epoch 00410: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0487 - mse: 11.0487 - val_loss: 21.5590 - val_mse: 21.5590\n",
      "Epoch 411/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.8298 - mse: 13.8298\n",
      "Epoch 00411: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.2361 - mse: 12.2361 - val_loss: 25.7733 - val_mse: 25.7733\n",
      "Epoch 412/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.2441 - mse: 14.2441\n",
      "Epoch 00412: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.6597 - mse: 17.6597 - val_loss: 23.0572 - val_mse: 23.0572\n",
      "Epoch 413/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.2302 - mse: 9.2302\n",
      "Epoch 00413: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.3906 - mse: 16.3906 - val_loss: 29.9365 - val_mse: 29.9365\n",
      "Epoch 414/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.6351 - mse: 13.6351\n",
      "Epoch 00414: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.0899 - mse: 14.0899 - val_loss: 23.9807 - val_mse: 23.9807\n",
      "Epoch 415/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7236 - mse: 8.7236\n",
      "Epoch 00415: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.0482 - mse: 14.0482 - val_loss: 22.9939 - val_mse: 22.9939\n",
      "Epoch 416/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.4176 - mse: 13.4176\n",
      "Epoch 00416: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.9103 - mse: 12.9103 - val_loss: 22.8183 - val_mse: 22.8183\n",
      "Epoch 417/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8913 - mse: 8.8913\n",
      "Epoch 00417: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.5592 - mse: 12.5592 - val_loss: 21.1481 - val_mse: 21.1481\n",
      "Epoch 418/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4879 - mse: 8.4879\n",
      "Epoch 00418: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2889 - mse: 11.2889 - val_loss: 27.2396 - val_mse: 27.2396\n",
      "Epoch 419/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.4775 - mse: 13.4775\n",
      "Epoch 00419: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3322 - mse: 12.3322 - val_loss: 22.1349 - val_mse: 22.1349\n",
      "Epoch 420/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8297 - mse: 8.8297\n",
      "Epoch 00420: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.3625 - mse: 14.3625 - val_loss: 22.6967 - val_mse: 22.6967\n",
      "Epoch 421/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2127 - mse: 8.2127\n",
      "Epoch 00421: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.6253 - mse: 11.6253 - val_loss: 20.7668 - val_mse: 20.7668\n",
      "Epoch 422/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6777 - mse: 6.6777\n",
      "Epoch 00422: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5041 - mse: 10.5041 - val_loss: 23.5405 - val_mse: 23.5405\n",
      "Epoch 423/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.0934 - mse: 14.0934\n",
      "Epoch 00423: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8772 - mse: 12.8772 - val_loss: 24.2913 - val_mse: 24.2913\n",
      "Epoch 424/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5737 - mse: 8.5737\n",
      "Epoch 00424: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.6075 - mse: 11.6075 - val_loss: 20.1397 - val_mse: 20.1397\n",
      "Epoch 425/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5100 - mse: 8.5100\n",
      "Epoch 00425: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4187 - mse: 10.4187 - val_loss: 22.0313 - val_mse: 22.0313\n",
      "Epoch 426/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.3983 - mse: 7.3983\n",
      "Epoch 00426: val_mse did not improve from 20.10545\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9358 - mse: 9.9358 - val_loss: 23.3663 - val_mse: 23.3663\n",
      "Epoch 427/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9222 - mse: 5.9222\n",
      "Epoch 00427: val_mse improved from 20.10545 to 19.87023, saving model to ./model/427-19.8702.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.5636 - mse: 9.5636 - val_loss: 19.8702 - val_mse: 19.8702\n",
      "Epoch 428/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.1392 - mse: 7.1392\n",
      "Epoch 00428: val_mse did not improve from 19.87023\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.4801 - mse: 9.4801 - val_loss: 19.9926 - val_mse: 19.9926\n",
      "Epoch 429/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1456 - mse: 6.1456\n",
      "Epoch 00429: val_mse improved from 19.87023 to 19.53690, saving model to ./model/429-19.5369.hdf5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.3800 - mse: 9.3800 - val_loss: 19.5369 - val_mse: 19.5369\n",
      "Epoch 430/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8470 - mse: 10.8470\n",
      "Epoch 00430: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.3720 - mse: 9.3720 - val_loss: 21.5590 - val_mse: 21.5590\n",
      "Epoch 431/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.5147 - mse: 7.5147\n",
      "Epoch 00431: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7904 - mse: 9.7904 - val_loss: 21.4800 - val_mse: 21.4800\n",
      "Epoch 432/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2089 - mse: 11.2089\n",
      "Epoch 00432: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.0652 - mse: 13.0652 - val_loss: 23.4557 - val_mse: 23.4557\n",
      "Epoch 433/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7320 - mse: 6.7320\n",
      "Epoch 00433: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.8296 - mse: 10.8296 - val_loss: 20.6573 - val_mse: 20.6573\n",
      "Epoch 434/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7618 - mse: 8.7618\n",
      "Epoch 00434: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1578 - mse: 10.1578 - val_loss: 23.1451 - val_mse: 23.1451\n",
      "Epoch 435/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6039 - mse: 6.6039\n",
      "Epoch 00435: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.2994 - mse: 10.2994 - val_loss: 19.5545 - val_mse: 19.5545\n",
      "Epoch 436/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.8390 - mse: 6.8390\n",
      "Epoch 00436: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9004 - mse: 9.9004 - val_loss: 23.9141 - val_mse: 23.9141\n",
      "Epoch 437/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.1368 - mse: 13.1368\n",
      "Epoch 00437: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.5377 - mse: 11.5377 - val_loss: 25.1417 - val_mse: 25.1417\n",
      "Epoch 438/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.9124 - mse: 14.9124\n",
      "Epoch 00438: val_mse did not improve from 19.53690\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4418 - mse: 10.4418 - val_loss: 20.7741 - val_mse: 20.7741\n",
      "Epoch 439/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.6478 - mse: 12.6478\n",
      "Epoch 00439: val_mse improved from 19.53690 to 19.27472, saving model to ./model/439-19.2747.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.2682 - mse: 9.2682 - val_loss: 19.2747 - val_mse: 19.2747\n",
      "Epoch 440/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.0813 - mse: 9.0813\n",
      "Epoch 00440: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1542 - mse: 9.1542 - val_loss: 20.2131 - val_mse: 20.2131\n",
      "Epoch 441/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7221 - mse: 5.7221\n",
      "Epoch 00441: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.4985 - mse: 9.4985 - val_loss: 20.2934 - val_mse: 20.2934\n",
      "Epoch 442/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.4488 - mse: 13.4488\n",
      "Epoch 00442: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1071 - mse: 10.1071 - val_loss: 20.4980 - val_mse: 20.4980\n",
      "Epoch 443/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6031 - mse: 6.6031\n",
      "Epoch 00443: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0507 - mse: 9.0507 - val_loss: 20.2345 - val_mse: 20.2345\n",
      "Epoch 444/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.6553 - mse: 4.6553\n",
      "Epoch 00444: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7656 - mse: 9.7656 - val_loss: 21.6062 - val_mse: 21.6062\n",
      "Epoch 445/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.9287 - mse: 7.9287\n",
      "Epoch 00445: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2347 - mse: 9.2347 - val_loss: 19.5289 - val_mse: 19.5289\n",
      "Epoch 446/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7463 - mse: 5.7463\n",
      "Epoch 00446: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.0361 - mse: 10.0361 - val_loss: 25.0297 - val_mse: 25.0297\n",
      "Epoch 447/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.8989 - mse: 6.8989\n",
      "Epoch 00447: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3745 - mse: 12.3745 - val_loss: 19.9099 - val_mse: 19.9099\n",
      "Epoch 448/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.7740 - mse: 10.7740\n",
      "Epoch 00448: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.7352 - mse: 11.7352 - val_loss: 24.9302 - val_mse: 24.9302\n",
      "Epoch 449/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6667 - mse: 6.6667\n",
      "Epoch 00449: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7173 - mse: 9.7173 - val_loss: 22.5653 - val_mse: 22.5653\n",
      "Epoch 450/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.9603 - mse: 4.9603\n",
      "Epoch 00450: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4695 - mse: 10.4695 - val_loss: 19.9170 - val_mse: 19.9170\n",
      "Epoch 451/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1298 - mse: 6.1298\n",
      "Epoch 00451: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2376 - mse: 11.2376 - val_loss: 33.6610 - val_mse: 33.6610\n",
      "Epoch 452/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.7225 - mse: 15.7225\n",
      "Epoch 00452: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.6887 - mse: 11.6887 - val_loss: 19.7371 - val_mse: 19.7371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5555 - mse: 5.5555\n",
      "Epoch 00453: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.5377 - mse: 12.5377 - val_loss: 24.5561 - val_mse: 24.5561\n",
      "Epoch 454/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20.5071 - mse: 20.5071\n",
      "Epoch 00454: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 13.2276 - mse: 13.2276 - val_loss: 22.0329 - val_mse: 22.0329\n",
      "Epoch 455/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.7511 - mse: 15.7511\n",
      "Epoch 00455: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.4298 - mse: 11.4298 - val_loss: 20.5203 - val_mse: 20.5203\n",
      "Epoch 456/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5642 - mse: 12.5642\n",
      "Epoch 00456: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.6014 - mse: 10.6014 - val_loss: 19.7051 - val_mse: 19.7051\n",
      "Epoch 457/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7013 - mse: 6.7013\n",
      "Epoch 00457: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.6910 - mse: 9.6910 - val_loss: 20.8759 - val_mse: 20.8759\n",
      "Epoch 458/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.5301 - mse: 6.5301\n",
      "Epoch 00458: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1117 - mse: 9.1117 - val_loss: 20.2920 - val_mse: 20.2920\n",
      "Epoch 459/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8533 - mse: 10.8533\n",
      "Epoch 00459: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0323 - mse: 9.0323 - val_loss: 20.2015 - val_mse: 20.2015\n",
      "Epoch 460/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.4985 - mse: 9.4985\n",
      "Epoch 00460: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9542 - mse: 8.9542 - val_loss: 20.1119 - val_mse: 20.1119\n",
      "Epoch 461/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.6153 - mse: 16.6153\n",
      "Epoch 00461: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1673 - mse: 10.1673 - val_loss: 19.7215 - val_mse: 19.7215\n",
      "Epoch 462/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4048 - mse: 8.4048\n",
      "Epoch 00462: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0326 - mse: 9.0326 - val_loss: 23.3668 - val_mse: 23.3668\n",
      "Epoch 463/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.5733 - mse: 11.5733\n",
      "Epoch 00463: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1647 - mse: 10.1647 - val_loss: 23.0047 - val_mse: 23.0047\n",
      "Epoch 464/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.0975 - mse: 15.0975\n",
      "Epoch 00464: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8768 - mse: 9.8768 - val_loss: 19.7088 - val_mse: 19.7088\n",
      "Epoch 465/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6411 - mse: 6.6411\n",
      "Epoch 00465: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0687 - mse: 9.0687 - val_loss: 19.8042 - val_mse: 19.8042\n",
      "Epoch 466/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.9670 - mse: 8.9670\n",
      "Epoch 00466: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6975 - mse: 8.6975 - val_loss: 21.4667 - val_mse: 21.4667\n",
      "Epoch 467/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.6870 - mse: 10.6870\n",
      "Epoch 00467: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9599 - mse: 8.9599 - val_loss: 20.7567 - val_mse: 20.7567\n",
      "Epoch 468/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7321 - mse: 7.7321\n",
      "Epoch 00468: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.4486 - mse: 9.4486 - val_loss: 21.1707 - val_mse: 21.1707\n",
      "Epoch 469/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8094 - mse: 8.8094\n",
      "Epoch 00469: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8515 - mse: 8.8515 - val_loss: 20.6184 - val_mse: 20.6184\n",
      "Epoch 470/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8761 - mse: 10.8761\n",
      "Epoch 00470: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1932 - mse: 9.1932 - val_loss: 20.1647 - val_mse: 20.1647\n",
      "Epoch 471/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7012 - mse: 7.7012\n",
      "Epoch 00471: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 11.6008 - mse: 11.6008 - val_loss: 19.6647 - val_mse: 19.6647\n",
      "Epoch 472/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.5115 - mse: 10.5115\n",
      "Epoch 00472: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.0892 - mse: 15.0892 - val_loss: 20.0116 - val_mse: 20.0116\n",
      "Epoch 473/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.8465 - mse: 11.8465\n",
      "Epoch 00473: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0197 - mse: 11.0197 - val_loss: 23.7501 - val_mse: 23.7501\n",
      "Epoch 474/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5105 - mse: 12.5105\n",
      "Epoch 00474: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0774 - mse: 11.0774 - val_loss: 20.7907 - val_mse: 20.7907\n",
      "Epoch 475/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7219 - mse: 6.7219\n",
      "Epoch 00475: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2818 - mse: 9.2818 - val_loss: 19.9037 - val_mse: 19.9037\n",
      "Epoch 476/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.5171 - mse: 6.5171\n",
      "Epoch 00476: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1959 - mse: 10.1959 - val_loss: 25.4511 - val_mse: 25.4511\n",
      "Epoch 477/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.5376 - mse: 11.5376\n",
      "Epoch 00477: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7267 - mse: 9.7267 - val_loss: 21.5041 - val_mse: 21.5041\n",
      "Epoch 478/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1354 - mse: 6.1354\n",
      "Epoch 00478: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2122 - mse: 9.2122 - val_loss: 19.8551 - val_mse: 19.8551\n",
      "Epoch 479/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5955 - mse: 5.5955\n",
      "Epoch 00479: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5189 - mse: 8.5189 - val_loss: 19.4898 - val_mse: 19.4898\n",
      "Epoch 480/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1838 - mse: 11.1838\n",
      "Epoch 00480: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9474 - mse: 8.9474 - val_loss: 20.5587 - val_mse: 20.5587\n",
      "Epoch 481/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7090 - mse: 5.7090\n",
      "Epoch 00481: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9375 - mse: 8.9375 - val_loss: 20.3879 - val_mse: 20.3879\n",
      "Epoch 482/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.9567 - mse: 11.9567\n",
      "Epoch 00482: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.6976 - mse: 9.6976 - val_loss: 23.1080 - val_mse: 23.1080\n",
      "Epoch 483/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.0849 - mse: 5.0849\n",
      "Epoch 00483: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2081 - mse: 9.2081 - val_loss: 20.3651 - val_mse: 20.3651\n",
      "Epoch 484/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 12.4487 - mse: 12.4487\n",
      "Epoch 00484: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2813 - mse: 9.2813 - val_loss: 21.9263 - val_mse: 21.9263\n",
      "Epoch 485/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.9041 - mse: 7.9041\n",
      "Epoch 00485: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.7401 - mse: 10.7401 - val_loss: 19.9732 - val_mse: 19.9732\n",
      "Epoch 486/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.1283 - mse: 9.1283\n",
      "Epoch 00486: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9992 - mse: 8.9992 - val_loss: 20.1210 - val_mse: 20.1210\n",
      "Epoch 487/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.1869 - mse: 8.1869\n",
      "Epoch 00487: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3401 - mse: 8.3401 - val_loss: 21.3244 - val_mse: 21.3244\n",
      "Epoch 488/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.0510 - mse: 8.0510\n",
      "Epoch 00488: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9315 - mse: 8.9315 - val_loss: 19.7487 - val_mse: 19.7487\n",
      "Epoch 489/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.8371 - mse: 3.8371\n",
      "Epoch 00489: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5797 - mse: 8.5797 - val_loss: 19.5288 - val_mse: 19.5288\n",
      "Epoch 490/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.8029 - mse: 6.8029\n",
      "Epoch 00490: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1686 - mse: 10.1686 - val_loss: 19.3213 - val_mse: 19.3213\n",
      "Epoch 491/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.5976 - mse: 14.5976\n",
      "Epoch 00491: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6111 - mse: 8.6111 - val_loss: 20.6213 - val_mse: 20.6213\n",
      "Epoch 492/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.1404 - mse: 7.1404\n",
      "Epoch 00492: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.7792 - mse: 8.7792 - val_loss: 20.0421 - val_mse: 20.0421\n",
      "Epoch 493/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.7805 - mse: 10.7805\n",
      "Epoch 00493: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.7789 - mse: 8.7789 - val_loss: 21.3299 - val_mse: 21.3299\n",
      "Epoch 494/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.6199 - mse: 9.6199\n",
      "Epoch 00494: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2168 - mse: 9.2168 - val_loss: 25.0928 - val_mse: 25.0928\n",
      "Epoch 495/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.6469 - mse: 4.6469\n",
      "Epoch 00495: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1329 - mse: 12.1329 - val_loss: 21.0821 - val_mse: 21.0821\n",
      "Epoch 496/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.3781 - mse: 6.3781\n",
      "Epoch 00496: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2320 - mse: 11.2320 - val_loss: 20.6982 - val_mse: 20.6982\n",
      "Epoch 497/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.9247 - mse: 3.9247\n",
      "Epoch 00497: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9922 - mse: 8.9922 - val_loss: 19.9370 - val_mse: 19.9370\n",
      "Epoch 498/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2452 - mse: 6.2452\n",
      "Epoch 00498: val_mse did not improve from 19.27472\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1495 - mse: 9.1495 - val_loss: 21.1894 - val_mse: 21.1894\n",
      "Epoch 499/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2723 - mse: 13.2723\n",
      "Epoch 00499: val_mse improved from 19.27472 to 19.17546, saving model to ./model/499-19.1755.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.5139 - mse: 9.5139 - val_loss: 19.1755 - val_mse: 19.1755\n",
      "Epoch 500/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6736 - mse: 6.6736\n",
      "Epoch 00500: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5262 - mse: 8.5262 - val_loss: 20.2644 - val_mse: 20.2644\n",
      "Epoch 501/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6796 - mse: 8.6796\n",
      "Epoch 00501: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5988 - mse: 8.5988 - val_loss: 20.7830 - val_mse: 20.7830\n",
      "Epoch 502/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2692 - mse: 6.2692\n",
      "Epoch 00502: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8877 - mse: 8.8877 - val_loss: 19.5090 - val_mse: 19.5090\n",
      "Epoch 503/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.3351 - mse: 10.3351\n",
      "Epoch 00503: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1136 - mse: 9.1136 - val_loss: 23.8418 - val_mse: 23.8418\n",
      "Epoch 504/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 19.6110 - mse: 19.6110\n",
      "Epoch 00504: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8931 - mse: 9.8931 - val_loss: 22.2777 - val_mse: 22.2777\n",
      "Epoch 505/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.0385 - mse: 10.0385\n",
      "Epoch 00505: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.5240 - mse: 9.5240 - val_loss: 23.3994 - val_mse: 23.3994\n",
      "Epoch 506/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.0929 - mse: 21.0929\n",
      "Epoch 00506: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5582 - mse: 10.5582 - val_loss: 31.3131 - val_mse: 31.3131\n",
      "Epoch 507/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.4647 - mse: 12.4647\n",
      "Epoch 00507: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.3304 - mse: 14.3304 - val_loss: 19.5939 - val_mse: 19.5939\n",
      "Epoch 508/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.5761 - mse: 9.5761\n",
      "Epoch 00508: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.0340 - mse: 10.0340 - val_loss: 23.2297 - val_mse: 23.2297\n",
      "Epoch 509/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23.4983 - mse: 23.4983\n",
      "Epoch 00509: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.3486 - mse: 12.3486 - val_loss: 23.1233 - val_mse: 23.1233\n",
      "Epoch 510/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.3409 - mse: 10.3409\n",
      "Epoch 00510: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9795 - mse: 9.9795 - val_loss: 20.9201 - val_mse: 20.9201\n",
      "Epoch 511/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.2433 - mse: 13.2433\n",
      "Epoch 00511: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0844 - mse: 9.0844 - val_loss: 22.9863 - val_mse: 22.9863\n",
      "Epoch 512/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.0063 - mse: 9.0063\n",
      "Epoch 00512: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.7700 - mse: 8.7700 - val_loss: 19.8956 - val_mse: 19.8956\n",
      "Epoch 513/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.5844 - mse: 13.5844\n",
      "Epoch 00513: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4341 - mse: 8.4341 - val_loss: 20.2607 - val_mse: 20.2607\n",
      "Epoch 514/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.9543 - mse: 4.9543\n",
      "Epoch 00514: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3363 - mse: 8.3363 - val_loss: 19.9072 - val_mse: 19.9072\n",
      "Epoch 515/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6807 - mse: 8.6807\n",
      "Epoch 00515: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4336 - mse: 8.4336 - val_loss: 24.3593 - val_mse: 24.3593\n",
      "Epoch 516/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 15.5275 - mse: 15.5275\n",
      "Epoch 00516: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3541 - mse: 9.3541 - val_loss: 21.8942 - val_mse: 21.8942\n",
      "Epoch 517/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4020 - mse: 8.4020\n",
      "Epoch 00517: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0303 - mse: 8.0303 - val_loss: 20.5108 - val_mse: 20.5108\n",
      "Epoch 518/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.4700 - mse: 9.4700\n",
      "Epoch 00518: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7784 - mse: 7.7784 - val_loss: 21.0302 - val_mse: 21.0302\n",
      "Epoch 519/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.3241 - mse: 7.3241\n",
      "Epoch 00519: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3473 - mse: 8.3473 - val_loss: 21.7460 - val_mse: 21.7460\n",
      "Epoch 520/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.7598 - mse: 9.7598\n",
      "Epoch 00520: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4811 - mse: 8.4811 - val_loss: 20.2725 - val_mse: 20.2725\n",
      "Epoch 521/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 16.9406 - mse: 16.9406\n",
      "Epoch 00521: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2690 - mse: 9.2690 - val_loss: 20.2606 - val_mse: 20.2606\n",
      "Epoch 522/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4143 - mse: 7.4143\n",
      "Epoch 00522: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8845 - mse: 8.8845 - val_loss: 19.8521 - val_mse: 19.8521\n",
      "Epoch 523/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.8495 - mse: 4.8495\n",
      "Epoch 00523: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0028 - mse: 8.0028 - val_loss: 19.4768 - val_mse: 19.4768\n",
      "Epoch 524/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5808 - mse: 5.5808\n",
      "Epoch 00524: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9793 - mse: 7.9793 - val_loss: 19.5991 - val_mse: 19.5991\n",
      "Epoch 525/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.2264 - mse: 7.2264\n",
      "Epoch 00525: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0967 - mse: 8.0967 - val_loss: 19.9268 - val_mse: 19.9268\n",
      "Epoch 526/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6151 - mse: 8.6151\n",
      "Epoch 00526: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9648 - mse: 7.9648 - val_loss: 19.9692 - val_mse: 19.9692\n",
      "Epoch 527/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9156 - mse: 5.9156\n",
      "Epoch 00527: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1554 - mse: 8.1554 - val_loss: 21.0931 - val_mse: 21.0931\n",
      "Epoch 528/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.8856 - mse: 7.8856\n",
      "Epoch 00528: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1764 - mse: 8.1764 - val_loss: 23.4079 - val_mse: 23.4079\n",
      "Epoch 529/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.6296 - mse: 9.6296\n",
      "Epoch 00529: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8716 - mse: 8.8716 - val_loss: 22.1587 - val_mse: 22.1587\n",
      "Epoch 530/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4493 - mse: 8.4493\n",
      "Epoch 00530: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9464 - mse: 7.9464 - val_loss: 21.1950 - val_mse: 21.1950\n",
      "Epoch 531/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.3696 - mse: 13.3696\n",
      "Epoch 00531: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.0575 - mse: 9.0575 - val_loss: 22.1386 - val_mse: 22.1386\n",
      "Epoch 532/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.9400 - mse: 6.9400\n",
      "Epoch 00532: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3599 - mse: 9.3599 - val_loss: 23.8217 - val_mse: 23.8217\n",
      "Epoch 533/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.3039 - mse: 9.3039\n",
      "Epoch 00533: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6758 - mse: 8.6758 - val_loss: 21.6616 - val_mse: 21.6616\n",
      "Epoch 534/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.9963 - mse: 2.9963\n",
      "Epoch 00534: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.2501 - mse: 8.2501 - val_loss: 20.8560 - val_mse: 20.8560\n",
      "Epoch 535/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2488 - mse: 8.2488\n",
      "Epoch 00535: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4041 - mse: 8.4041 - val_loss: 19.7705 - val_mse: 19.7705\n",
      "Epoch 536/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.9764 - mse: 9.9764\n",
      "Epoch 00536: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.4878 - mse: 7.4878 - val_loss: 20.2748 - val_mse: 20.2748\n",
      "Epoch 537/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.1135 - mse: 11.1135\n",
      "Epoch 00537: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9722 - mse: 7.9722 - val_loss: 21.2261 - val_mse: 21.2261\n",
      "Epoch 538/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4204 - mse: 7.4204\n",
      "Epoch 00538: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8631 - mse: 7.8631 - val_loss: 19.8887 - val_mse: 19.8887\n",
      "Epoch 539/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6769 - mse: 8.6769\n",
      "Epoch 00539: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.4720 - mse: 7.4720 - val_loss: 20.1622 - val_mse: 20.1622\n",
      "Epoch 540/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5147 - mse: 5.5147\n",
      "Epoch 00540: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8301 - mse: 7.8301 - val_loss: 21.0554 - val_mse: 21.0554\n",
      "Epoch 541/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4414 - mse: 7.4414\n",
      "Epoch 00541: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8517 - mse: 7.8517 - val_loss: 21.0924 - val_mse: 21.0924\n",
      "Epoch 542/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.8500 - mse: 10.8500\n",
      "Epoch 00542: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0607 - mse: 8.0607 - val_loss: 20.3325 - val_mse: 20.3325\n",
      "Epoch 543/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.2282 - mse: 10.2282\n",
      "Epoch 00543: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.6877 - mse: 7.6877 - val_loss: 20.6636 - val_mse: 20.6636\n",
      "Epoch 544/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2818 - mse: 6.2818\n",
      "Epoch 00544: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8123 - mse: 7.8123 - val_loss: 19.9321 - val_mse: 19.9321\n",
      "Epoch 545/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7537 - mse: 7.7537\n",
      "Epoch 00545: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2569 - mse: 7.2569 - val_loss: 20.8667 - val_mse: 20.8667\n",
      "Epoch 546/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2527 - mse: 8.2527\n",
      "Epoch 00546: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3672 - mse: 7.3672 - val_loss: 20.3589 - val_mse: 20.3589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8912 - mse: 8.8912\n",
      "Epoch 00547: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3787 - mse: 7.3787 - val_loss: 19.9710 - val_mse: 19.9710\n",
      "Epoch 548/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2082 - mse: 8.2082\n",
      "Epoch 00548: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3218 - mse: 8.3218 - val_loss: 19.5957 - val_mse: 19.5957\n",
      "Epoch 549/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.2895 - mse: 7.2895\n",
      "Epoch 00549: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.5453 - mse: 7.5453 - val_loss: 20.6853 - val_mse: 20.6853\n",
      "Epoch 550/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6404 - mse: 8.6404\n",
      "Epoch 00550: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0289 - mse: 8.0289 - val_loss: 21.3767 - val_mse: 21.3767\n",
      "Epoch 551/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.2166 - mse: 9.2166\n",
      "Epoch 00551: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8667 - mse: 7.8667 - val_loss: 20.2640 - val_mse: 20.2640\n",
      "Epoch 552/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5203 - mse: 2.5203\n",
      "Epoch 00552: val_mse did not improve from 19.17546\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3445 - mse: 8.3445 - val_loss: 21.4640 - val_mse: 21.4640\n",
      "Epoch 553/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.6918 - mse: 5.6918\n",
      "Epoch 00553: val_mse improved from 19.17546 to 19.08760, saving model to ./model/553-19.0876.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.0183 - mse: 9.0183 - val_loss: 19.0876 - val_mse: 19.0876\n",
      "Epoch 554/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7916 - mse: 5.7916\n",
      "Epoch 00554: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3267 - mse: 9.3267 - val_loss: 19.7565 - val_mse: 19.7565\n",
      "Epoch 555/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.0173 - mse: 8.0173\n",
      "Epoch 00555: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7551 - mse: 9.7551 - val_loss: 24.1857 - val_mse: 24.1857\n",
      "Epoch 556/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.6847 - mse: 11.6847\n",
      "Epoch 00556: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8101 - mse: 12.8101 - val_loss: 27.7600 - val_mse: 27.7600\n",
      "Epoch 557/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.4011 - mse: 21.4011\n",
      "Epoch 00557: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.4026 - mse: 12.4026 - val_loss: 20.8497 - val_mse: 20.8497\n",
      "Epoch 558/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.9376 - mse: 7.9376\n",
      "Epoch 00558: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.8179 - mse: 11.8179 - val_loss: 21.3606 - val_mse: 21.3606\n",
      "Epoch 559/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.5566 - mse: 10.5566\n",
      "Epoch 00559: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.3393 - mse: 10.3393 - val_loss: 25.9291 - val_mse: 25.9291\n",
      "Epoch 560/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.6404 - mse: 10.6404\n",
      "Epoch 00560: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.7583 - mse: 10.7583 - val_loss: 23.0585 - val_mse: 23.0585\n",
      "Epoch 561/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.8483 - mse: 12.8483\n",
      "Epoch 00561: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4757 - mse: 10.4757 - val_loss: 23.3673 - val_mse: 23.3673\n",
      "Epoch 562/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.3817 - mse: 10.3817\n",
      "Epoch 00562: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6470 - mse: 8.6470 - val_loss: 22.9590 - val_mse: 22.9590\n",
      "Epoch 563/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.6535 - mse: 10.6535\n",
      "Epoch 00563: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.2056 - mse: 10.2056 - val_loss: 24.9925 - val_mse: 24.9925\n",
      "Epoch 564/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2439 - mse: 8.2439\n",
      "Epoch 00564: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.0727 - mse: 12.0727 - val_loss: 21.1129 - val_mse: 21.1129\n",
      "Epoch 565/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.3329 - mse: 6.3329\n",
      "Epoch 00565: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.2228 - mse: 9.2228 - val_loss: 19.3049 - val_mse: 19.3049\n",
      "Epoch 566/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.0821 - mse: 3.0821\n",
      "Epoch 00566: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7220 - mse: 7.7220 - val_loss: 20.3375 - val_mse: 20.3375\n",
      "Epoch 567/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.0694 - mse: 4.0694\n",
      "Epoch 00567: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6462 - mse: 8.6462 - val_loss: 20.7851 - val_mse: 20.7851\n",
      "Epoch 568/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.3271 - mse: 4.3271\n",
      "Epoch 00568: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.5140 - mse: 9.5140 - val_loss: 19.6898 - val_mse: 19.6898\n",
      "Epoch 569/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.8532 - mse: 3.8532\n",
      "Epoch 00569: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9165 - mse: 8.9165 - val_loss: 20.5845 - val_mse: 20.5845\n",
      "Epoch 570/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.6288 - mse: 8.6288\n",
      "Epoch 00570: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8347 - mse: 8.8347 - val_loss: 20.1487 - val_mse: 20.1487\n",
      "Epoch 571/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.3774 - mse: 6.3774\n",
      "Epoch 00571: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3357 - mse: 9.3357 - val_loss: 24.6470 - val_mse: 24.6470\n",
      "Epoch 572/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.1274 - mse: 14.1274\n",
      "Epoch 00572: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3071 - mse: 9.3071 - val_loss: 21.3740 - val_mse: 21.3740\n",
      "Epoch 573/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.6448 - mse: 5.6448\n",
      "Epoch 00573: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8792 - mse: 9.8792 - val_loss: 20.5452 - val_mse: 20.5452\n",
      "Epoch 574/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.5633 - mse: 6.5633\n",
      "Epoch 00574: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4330 - mse: 8.4330 - val_loss: 20.3277 - val_mse: 20.3277\n",
      "Epoch 575/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.3822 - mse: 9.3822\n",
      "Epoch 00575: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0853 - mse: 8.0853 - val_loss: 20.6537 - val_mse: 20.6537\n",
      "Epoch 576/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5373 - mse: 5.5373\n",
      "Epoch 00576: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9753 - mse: 9.9753 - val_loss: 20.1005 - val_mse: 20.1005\n",
      "Epoch 577/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.9935 - mse: 9.9935\n",
      "Epoch 00577: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.3589 - mse: 8.3589 - val_loss: 21.3313 - val_mse: 21.3313\n",
      "Epoch 578/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7904 - mse: 7.7904\n",
      "Epoch 00578: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6582 - mse: 8.6582 - val_loss: 23.9938 - val_mse: 23.9938\n",
      "Epoch 579/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7160 - mse: 5.7160\n",
      "Epoch 00579: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.3349 - mse: 9.3349 - val_loss: 20.3860 - val_mse: 20.3860\n",
      "Epoch 580/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2379 - mse: 6.2379\n",
      "Epoch 00580: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9662 - mse: 9.9662 - val_loss: 22.1729 - val_mse: 22.1729\n",
      "Epoch 581/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7978 - mse: 12.7978\n",
      "Epoch 00581: val_mse did not improve from 19.08760\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.6670 - mse: 9.6670 - val_loss: 21.7488 - val_mse: 21.7488\n",
      "Epoch 582/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.0782 - mse: 11.0782\n",
      "Epoch 00582: val_mse improved from 19.08760 to 18.36450, saving model to ./model/582-18.3645.hdf5\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.1474 - mse: 8.1474 - val_loss: 18.3645 - val_mse: 18.3645\n",
      "Epoch 583/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.5431 - mse: 8.5431\n",
      "Epoch 00583: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8116 - mse: 7.8116 - val_loss: 19.8382 - val_mse: 19.8382\n",
      "Epoch 584/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2011 - mse: 6.2011\n",
      "Epoch 00584: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4626 - mse: 8.4626 - val_loss: 22.6500 - val_mse: 22.6500\n",
      "Epoch 585/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.0255 - mse: 9.0255\n",
      "Epoch 00585: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.4522 - mse: 14.4522 - val_loss: 20.6963 - val_mse: 20.6963\n",
      "Epoch 586/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.6631 - mse: 7.6631\n",
      "Epoch 00586: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.2422 - mse: 11.2422 - val_loss: 30.8522 - val_mse: 30.8522\n",
      "Epoch 587/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7038 - mse: 8.7038\n",
      "Epoch 00587: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5078 - mse: 10.5078 - val_loss: 20.9324 - val_mse: 20.9324\n",
      "Epoch 588/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0974 - mse: 6.0974\n",
      "Epoch 00588: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.4026 - mse: 10.4026 - val_loss: 22.1728 - val_mse: 22.1728\n",
      "Epoch 589/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.6226 - mse: 14.6226\n",
      "Epoch 00589: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.9645 - mse: 10.9645 - val_loss: 25.0345 - val_mse: 25.0345\n",
      "Epoch 590/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.1634 - mse: 10.1634\n",
      "Epoch 00590: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.5658 - mse: 10.5658 - val_loss: 19.7292 - val_mse: 19.7292\n",
      "Epoch 591/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.2499 - mse: 5.2499\n",
      "Epoch 00591: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.3664 - mse: 11.3664 - val_loss: 26.2502 - val_mse: 26.2502\n",
      "Epoch 592/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.9160 - mse: 17.9160\n",
      "Epoch 00592: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.7240 - mse: 10.7240 - val_loss: 25.0931 - val_mse: 25.0931\n",
      "Epoch 593/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1512 - mse: 6.1512\n",
      "Epoch 00593: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8140 - mse: 9.8140 - val_loss: 25.6283 - val_mse: 25.6283\n",
      "Epoch 594/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.0357 - mse: 10.0357\n",
      "Epoch 00594: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11.0438 - mse: 11.0438 - val_loss: 20.0144 - val_mse: 20.0144\n",
      "Epoch 595/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4133 - mse: 7.4133\n",
      "Epoch 00595: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.1047 - mse: 9.1047 - val_loss: 21.5615 - val_mse: 21.5615\n",
      "Epoch 596/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 17.8369 - mse: 17.8369\n",
      "Epoch 00596: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.9136 - mse: 8.9136 - val_loss: 19.2617 - val_mse: 19.2617\n",
      "Epoch 597/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.7657 - mse: 9.7657\n",
      "Epoch 00597: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.6029 - mse: 7.6029 - val_loss: 20.2932 - val_mse: 20.2932\n",
      "Epoch 598/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2151 - mse: 8.2151\n",
      "Epoch 00598: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.2120 - mse: 8.2120 - val_loss: 19.5181 - val_mse: 19.5181\n",
      "Epoch 599/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.7712 - mse: 5.7712\n",
      "Epoch 00599: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.5936 - mse: 7.5936 - val_loss: 19.9001 - val_mse: 19.9001\n",
      "Epoch 600/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.9146 - mse: 7.9146\n",
      "Epoch 00600: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3388 - mse: 7.3388 - val_loss: 21.0379 - val_mse: 21.0379\n",
      "Epoch 601/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.2058 - mse: 5.2058\n",
      "Epoch 00601: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7219 - mse: 7.7219 - val_loss: 20.5802 - val_mse: 20.5802\n",
      "Epoch 602/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.0060 - mse: 4.0060\n",
      "Epoch 00602: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0745 - mse: 8.0745 - val_loss: 19.4632 - val_mse: 19.4632\n",
      "Epoch 603/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.2854 - mse: 9.2854\n",
      "Epoch 00603: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5661 - mse: 8.5661 - val_loss: 20.7244 - val_mse: 20.7244\n",
      "Epoch 604/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0757 - mse: 7.0757\n",
      "Epoch 00604: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7185 - mse: 7.7185 - val_loss: 20.5403 - val_mse: 20.5403\n",
      "Epoch 605/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9546 - mse: 5.9546\n",
      "Epoch 00605: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.8353 - mse: 8.8353 - val_loss: 20.1321 - val_mse: 20.1321\n",
      "Epoch 606/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.2113 - mse: 4.2113\n",
      "Epoch 00606: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9337 - mse: 6.9337 - val_loss: 20.0762 - val_mse: 20.0762\n",
      "Epoch 607/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7313 - mse: 8.7313\n",
      "Epoch 00607: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8516 - mse: 6.8516 - val_loss: 20.0824 - val_mse: 20.0824\n",
      "Epoch 608/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.1071 - mse: 9.1071\n",
      "Epoch 00608: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5419 - mse: 8.5419 - val_loss: 19.9481 - val_mse: 19.9481\n",
      "Epoch 609/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 11.2211 - mse: 11.2211\n",
      "Epoch 00609: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8532 - mse: 7.8532 - val_loss: 19.8386 - val_mse: 19.8386\n",
      "Epoch 610/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.9191 - mse: 10.9191\n",
      "Epoch 00610: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.1405 - mse: 10.1405 - val_loss: 28.8780 - val_mse: 28.8780\n",
      "Epoch 611/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.4897 - mse: 11.4897\n",
      "Epoch 00611: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10.3313 - mse: 10.3313 - val_loss: 28.5647 - val_mse: 28.5647\n",
      "Epoch 612/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.0735 - mse: 12.0735\n",
      "Epoch 00612: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.1441 - mse: 12.1441 - val_loss: 20.2658 - val_mse: 20.2658\n",
      "Epoch 613/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9355 - mse: 5.9355\n",
      "Epoch 00613: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.7874 - mse: 9.7874 - val_loss: 20.4595 - val_mse: 20.4595\n",
      "Epoch 614/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.8909 - mse: 6.8909\n",
      "Epoch 00614: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3384 - mse: 7.3384 - val_loss: 20.5568 - val_mse: 20.5568\n",
      "Epoch 615/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.5291 - mse: 5.5291\n",
      "Epoch 00615: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7530 - mse: 7.7530 - val_loss: 20.0981 - val_mse: 20.0981\n",
      "Epoch 616/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.7706 - mse: 13.7706\n",
      "Epoch 00616: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9060 - mse: 7.9060 - val_loss: 20.0831 - val_mse: 20.0831\n",
      "Epoch 617/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.4350 - mse: 6.4350\n",
      "Epoch 00617: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7095 - mse: 6.7095 - val_loss: 19.7857 - val_mse: 19.7857\n",
      "Epoch 618/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0965 - mse: 7.0965\n",
      "Epoch 00618: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1796 - mse: 8.1796 - val_loss: 19.8773 - val_mse: 19.8773\n",
      "Epoch 619/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.1884 - mse: 9.1884\n",
      "Epoch 00619: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.2587 - mse: 8.2587 - val_loss: 20.0219 - val_mse: 20.0219\n",
      "Epoch 620/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.5752 - mse: 12.5752\n",
      "Epoch 00620: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4526 - mse: 6.4526 - val_loss: 21.3789 - val_mse: 21.3789\n",
      "Epoch 621/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.4344 - mse: 7.4344\n",
      "Epoch 00621: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9619 - mse: 6.9619 - val_loss: 20.1023 - val_mse: 20.1023\n",
      "Epoch 622/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0026 - mse: 6.0026\n",
      "Epoch 00622: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9065 - mse: 6.9065 - val_loss: 20.8552 - val_mse: 20.8552\n",
      "Epoch 623/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.9245 - mse: 6.9245\n",
      "Epoch 00623: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.9245 - mse: 7.9245 - val_loss: 19.7441 - val_mse: 19.7441\n",
      "Epoch 624/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.4699 - mse: 10.4699\n",
      "Epoch 00624: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.4581 - mse: 9.4581 - val_loss: 23.3175 - val_mse: 23.3175\n",
      "Epoch 625/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 10.1895 - mse: 10.1895\n",
      "Epoch 00625: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0326 - mse: 8.0326 - val_loss: 21.5843 - val_mse: 21.5843\n",
      "Epoch 626/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.3279 - mse: 6.3279\n",
      "Epoch 00626: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7105 - mse: 7.7105 - val_loss: 25.2701 - val_mse: 25.2701\n",
      "Epoch 627/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.2580 - mse: 6.2580\n",
      "Epoch 00627: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.7455 - mse: 7.7455 - val_loss: 21.8344 - val_mse: 21.8344\n",
      "Epoch 628/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.4349 - mse: 6.4349\n",
      "Epoch 00628: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1766 - mse: 7.1766 - val_loss: 19.7761 - val_mse: 19.7761\n",
      "Epoch 629/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.8339 - mse: 5.8339\n",
      "Epoch 00629: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7794 - mse: 6.7794 - val_loss: 19.1197 - val_mse: 19.1197\n",
      "Epoch 630/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.1801 - mse: 9.1801\n",
      "Epoch 00630: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7107 - mse: 6.7107 - val_loss: 20.6035 - val_mse: 20.6035\n",
      "Epoch 631/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0458 - mse: 6.0458\n",
      "Epoch 00631: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6331 - mse: 6.6331 - val_loss: 20.2154 - val_mse: 20.2154\n",
      "Epoch 632/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9286 - mse: 5.9286\n",
      "Epoch 00632: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4879 - mse: 6.4879 - val_loss: 19.6619 - val_mse: 19.6619\n",
      "Epoch 633/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.1362 - mse: 7.1362\n",
      "Epoch 00633: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5824 - mse: 6.5824 - val_loss: 21.3567 - val_mse: 21.3567\n",
      "Epoch 634/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.3005 - mse: 8.3005\n",
      "Epoch 00634: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5259 - mse: 6.5259 - val_loss: 19.6330 - val_mse: 19.6330\n",
      "Epoch 635/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.5314 - mse: 6.5314\n",
      "Epoch 00635: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7307 - mse: 6.7307 - val_loss: 20.0667 - val_mse: 20.0667\n",
      "Epoch 636/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.1042 - mse: 8.1042\n",
      "Epoch 00636: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5225 - mse: 6.5225 - val_loss: 19.6133 - val_mse: 19.6133\n",
      "Epoch 637/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0762 - mse: 6.0762\n",
      "Epoch 00637: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6753 - mse: 6.6753 - val_loss: 19.6893 - val_mse: 19.6893\n",
      "Epoch 638/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6865 - mse: 6.6865\n",
      "Epoch 00638: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7163 - mse: 6.7163 - val_loss: 21.2027 - val_mse: 21.2027\n",
      "Epoch 639/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.3721 - mse: 7.3721\n",
      "Epoch 00639: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.4257 - mse: 7.4257 - val_loss: 23.8690 - val_mse: 23.8690\n",
      "Epoch 640/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.2687 - mse: 7.2687\n",
      "Epoch 00640: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.8932 - mse: 7.8932 - val_loss: 21.3182 - val_mse: 21.3182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.0410 - mse: 6.0410\n",
      "Epoch 00641: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3082 - mse: 7.3082 - val_loss: 20.5988 - val_mse: 20.5988\n",
      "Epoch 642/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.1406 - mse: 5.1406\n",
      "Epoch 00642: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5472 - mse: 6.5472 - val_loss: 19.9877 - val_mse: 19.9877\n",
      "Epoch 643/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.8762 - mse: 4.8762\n",
      "Epoch 00643: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8089 - mse: 6.8089 - val_loss: 21.0033 - val_mse: 21.0033\n",
      "Epoch 644/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.8820 - mse: 6.8820\n",
      "Epoch 00644: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.3904 - mse: 6.3904 - val_loss: 20.4243 - val_mse: 20.4243\n",
      "Epoch 645/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.1098 - mse: 5.1098\n",
      "Epoch 00645: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5295 - mse: 6.5295 - val_loss: 19.6099 - val_mse: 19.6099\n",
      "Epoch 646/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.9846 - mse: 4.9846\n",
      "Epoch 00646: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.0942 - mse: 7.0942 - val_loss: 20.3710 - val_mse: 20.3710\n",
      "Epoch 647/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.7851 - mse: 8.7851\n",
      "Epoch 00647: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7874 - mse: 6.7874 - val_loss: 19.9120 - val_mse: 19.9120\n",
      "Epoch 648/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7035 - mse: 6.7035\n",
      "Epoch 00648: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6692 - mse: 6.6692 - val_loss: 20.1403 - val_mse: 20.1403\n",
      "Epoch 649/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0806 - mse: 7.0806\n",
      "Epoch 00649: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8558 - mse: 6.8558 - val_loss: 20.2511 - val_mse: 20.2511\n",
      "Epoch 650/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.3324 - mse: 8.3324\n",
      "Epoch 00650: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6917 - mse: 6.6917 - val_loss: 21.1544 - val_mse: 21.1544\n",
      "Epoch 651/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.4024 - mse: 5.4024\n",
      "Epoch 00651: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1845 - mse: 7.1845 - val_loss: 19.9123 - val_mse: 19.9123\n",
      "Epoch 652/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.8366 - mse: 4.8366\n",
      "Epoch 00652: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.5913 - mse: 6.5913 - val_loss: 21.0378 - val_mse: 21.0378\n",
      "Epoch 653/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.7082 - mse: 7.7082\n",
      "Epoch 00653: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4280 - mse: 6.4280 - val_loss: 20.2138 - val_mse: 20.2138\n",
      "Epoch 654/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.2020 - mse: 5.2020\n",
      "Epoch 00654: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4865 - mse: 6.4865 - val_loss: 19.8473 - val_mse: 19.8473\n",
      "Epoch 655/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.6060 - mse: 5.6060\n",
      "Epoch 00655: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4904 - mse: 6.4904 - val_loss: 20.2401 - val_mse: 20.2401\n",
      "Epoch 656/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.2881 - mse: 7.2881\n",
      "Epoch 00656: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8577 - mse: 6.8577 - val_loss: 20.1891 - val_mse: 20.1891\n",
      "Epoch 657/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.4853 - mse: 8.4853\n",
      "Epoch 00657: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1732 - mse: 7.1732 - val_loss: 20.4938 - val_mse: 20.4938\n",
      "Epoch 658/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.7016 - mse: 6.7016\n",
      "Epoch 00658: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6233 - mse: 6.6233 - val_loss: 20.2564 - val_mse: 20.2564\n",
      "Epoch 659/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.8586 - mse: 2.8586\n",
      "Epoch 00659: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.0499 - mse: 7.0499 - val_loss: 20.5348 - val_mse: 20.5348\n",
      "Epoch 660/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.2106 - mse: 5.2106\n",
      "Epoch 00660: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2856 - mse: 7.2856 - val_loss: 21.9616 - val_mse: 21.9616\n",
      "Epoch 661/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.2341 - mse: 8.2341\n",
      "Epoch 00661: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.9815 - mse: 9.9815 - val_loss: 27.7367 - val_mse: 27.7367\n",
      "Epoch 662/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.0969 - mse: 11.0969\n",
      "Epoch 00662: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8991 - mse: 9.8991 - val_loss: 28.7570 - val_mse: 28.7570\n",
      "Epoch 663/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.3186 - mse: 11.3186\n",
      "Epoch 00663: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.5878 - mse: 8.5878 - val_loss: 19.6215 - val_mse: 19.6214\n",
      "Epoch 664/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.6141 - mse: 5.6141\n",
      "Epoch 00664: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.6825 - mse: 8.6825 - val_loss: 20.0526 - val_mse: 20.0526\n",
      "Epoch 665/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.8108 - mse: 4.8108\n",
      "Epoch 00665: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.4589 - mse: 8.4589 - val_loss: 26.5503 - val_mse: 26.5503\n",
      "Epoch 666/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 12.7116 - mse: 12.7116\n",
      "Epoch 00666: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9.8054 - mse: 9.8054 - val_loss: 21.1427 - val_mse: 21.1427\n",
      "Epoch 667/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.7014 - mse: 3.7014\n",
      "Epoch 00667: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0024 - mse: 8.0024 - val_loss: 21.5095 - val_mse: 21.5095\n",
      "Epoch 668/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.4301 - mse: 4.4301\n",
      "Epoch 00668: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.6983 - mse: 7.6983 - val_loss: 21.3661 - val_mse: 21.3661\n",
      "Epoch 669/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.8738 - mse: 3.8738\n",
      "Epoch 00669: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9581 - mse: 6.9581 - val_loss: 22.3257 - val_mse: 22.3257\n",
      "Epoch 670/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 7.0444 - mse: 7.0444\n",
      "Epoch 00670: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.5070 - mse: 7.5070 - val_loss: 21.8294 - val_mse: 21.8294\n",
      "Epoch 671/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8488 - mse: 8.8488\n",
      "Epoch 00671: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.5659 - mse: 7.5659 - val_loss: 20.2703 - val_mse: 20.2703\n",
      "Epoch 672/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 9.5331 - mse: 9.5331\n",
      "Epoch 00672: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.2775 - mse: 7.2775 - val_loss: 21.1820 - val_mse: 21.1820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 11.5839 - mse: 11.5839\n",
      "Epoch 00673: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3746 - mse: 7.3746 - val_loss: 20.4693 - val_mse: 20.4693\n",
      "Epoch 674/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 4.0965 - mse: 4.0965\n",
      "Epoch 00674: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6799 - mse: 6.6799 - val_loss: 20.4724 - val_mse: 20.4724\n",
      "Epoch 675/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1492 - mse: 6.1492\n",
      "Epoch 00675: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8565 - mse: 6.8565 - val_loss: 22.6412 - val_mse: 22.6412\n",
      "Epoch 676/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1775 - mse: 6.1775\n",
      "Epoch 00676: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4198 - mse: 6.4198 - val_loss: 20.3384 - val_mse: 20.3384\n",
      "Epoch 677/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.0791 - mse: 3.0791\n",
      "Epoch 00677: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4107 - mse: 6.4107 - val_loss: 20.5977 - val_mse: 20.5977\n",
      "Epoch 678/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.9664 - mse: 5.9664\n",
      "Epoch 00678: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.8883 - mse: 6.8883 - val_loss: 20.0863 - val_mse: 20.0863\n",
      "Epoch 679/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.8803 - mse: 3.8803\n",
      "Epoch 00679: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.9597 - mse: 6.9597 - val_loss: 20.0248 - val_mse: 20.0248\n",
      "Epoch 680/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 8.8639 - mse: 8.8639\n",
      "Epoch 00680: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4336 - mse: 6.4336 - val_loss: 20.6519 - val_mse: 20.6519\n",
      "Epoch 681/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.1040 - mse: 6.1040\n",
      "Epoch 00681: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1601 - mse: 7.1601 - val_loss: 21.2367 - val_mse: 21.2367\n",
      "Epoch 682/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.4128 - mse: 3.4128\n",
      "Epoch 00682: val_mse did not improve from 18.36450\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.4398 - mse: 7.4398 - val_loss: 23.9398 - val_mse: 23.9398\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(X_train, Y_train, validation_split=0.33, epochs=5000, batch_size=30, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 22.600, 예상가격: 33.913\n",
      "실제가격: 50.000, 예상가격: 28.734\n",
      "실제가격: 23.000, 예상가격: 24.081\n",
      "실제가격: 8.300, 예상가격: 11.525\n",
      "실제가격: 21.200, 예상가격: 21.412\n",
      "실제가격: 19.900, 예상가격: 22.768\n",
      "실제가격: 20.600, 예상가격: 21.596\n",
      "실제가격: 18.700, 예상가격: 24.034\n",
      "실제가격: 16.100, 예상가격: 20.675\n",
      "실제가격: 18.600, 예상가격: 10.429\n"
     ]
    }
   ],
   "source": [
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "# flatten : 데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해 주는 함수\n",
    "\n",
    "# 10개 실제값과 예측값 비교\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 1개 정도를 제외하고는 9개의 집 가격을 어느정도 맞췄다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 학습 history 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_acc 에 학습 셋으로 측정한 정확도의 값을 저장\n",
    "y_vmse = history.history['val_mse']\n",
    "y_mse = history.history['mse']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_mse))\n",
    "len(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vmse, \"o\", c=\"red\", markersize=3, label='val_mse')\n",
    "plt.plot(x_len, y_mse, \"o\", c=\"blue\", markersize=3, label='mse')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 70)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
